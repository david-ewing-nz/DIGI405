\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{fontspec}
\setmainfont{TeX Gyre Pagella}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{enumitem}

\title{Key Insights from Meeting\\\large 16 January 2026}
\author{David Ewing}
\date{16 January 2026}

\begin{document}
\maketitle

\section*{Overview}

This document extracts the key insights and decision implications from Dr John Holmes' supervision meeting regarding the variational Bayes project. Each insight is presented with its context and practical implications for the report and implementation.

\section{Methodological Insights}

\subsection*{Insight 1: Laplace vs VB -- Different Approaches to the Same Approximation}
\textbf{[0:00:20]} ``You're replacing the posterior with a normal\ldots\ The difference is how you work out the mean and variance of that normal distribution.''

\textbf{Decision implication:} Both Laplace and VB use Gaussian approximations, but:
\begin{itemize}[noitemsep]
    \item \textbf{Laplace}: Mean = where first derivative = 0 (point estimate)
    \item \textbf{VB}: Mean = where \emph{expected value} of first derivative = 0 (expectation under $q$)
    \item Result: Different variances $\rightarrow$ different uncertainty estimates
\end{itemize}

\subsection*{Insight 2: Laplace Has Maximum Under-Dispersion}
\textbf{[0:01:53]} ``Laplace has the highest density at the peak\ldots\ it's the one that's most heavily underestimating the true uncertainty.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Laplace is \emph{more spiked} than VB
    \item Because it uses point estimates for derivatives (no averaging)
    \item \textbf{Decision: Skip Laplace in your report} -- not needed for the hierarchical model comparison
\end{itemize}

\subsection*{Insight 3: Focus on Variance, Not Modes}
\textbf{[0:04:10]} ``What you're more interested in is showing the changes in the posterior variance compared to the Gibbs sampling\ldots\ focus is much more on the variance.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item VB gets modes approximately correct
    \item VB gets \emph{shape} correct (Gammas look like Gammas)
    \item \textbf{The problem is the spread (variance) -- that's what to demonstrate}
    \item This is the core pedagogical message
\end{itemize}

\subsection*{Insight 4: Gibbs is the Gold Standard}
\textbf{[0:06:36]} ``That's why you're having to run these Gibbs samples alongside it\ldots\ if you take enough samples, you will get draws from the posterior distribution.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Gibbs (MCMC) = ground truth when no analytical posterior exists
    \item Slow but accurate
    \item \textbf{Decision: Use HMC/Stan as baseline for all comparisons}
\end{itemize}

\section{Variance Components -- The Core Challenge}

\subsection*{Insight 5: Variance Components Are Hardest}
\textbf{[0:07:37]} ``The thing that's hardest to do in this model is the variance components. It's not the betas and the u's. It's the variance components ($\tau_u$, $\tau_e$).''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item $\beta$s and $u$'s: VB does fine
    \item \textbf{Precisions/variances: VB struggles significantly}
    \item This is \emph{especially} true with small sample sizes
    \item \textbf{Core finding for your report}
\end{itemize}

\subsection*{Insight 6: Experimental Design -- Vary Group Sizes, Fix Total $N$}
\textbf{[0:07:37]} ``Do this model with multiple groups, changing the group sizes, but leaving the total number of observations unchanged.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Design decision:} Keep $N$ constant (e.g., $N = 500$)
    \item Vary number of groups ($Q$): 6, 10, 15, 25
    \item This changes observations per group level
    \item Controls for ``more data = better results'' criticism
    \item \textbf{This is your Model 3 experimental design}
\end{itemize}

\subsection*{Insight 7: Shrinkage -- The Core VB Weakness}
\textbf{[0:09:57]} ``The more times you see the same random effect level, the better you will do at estimating the variance components\ldots\ variational Bayes doesn't take shrinkage into account.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Few observations per level $\rightarrow$ heavy shrinkage in Bayesian estimation
    \item \textbf{VB's approximate posteriors don't capture this shrinkage}
    \item More observations per level $\rightarrow$ less shrinkage $\rightarrow$ VB does better
    \item \textbf{This explains the relationship between sample size and VB performance}
\end{itemize}

\section{Mathematical Understanding}

\subsection*{Insight 8: ELBO Measures Distribution Distance}
\textbf{[0:10:29]} ``The ELBO is measuring\ldots\ minimised distance between two distributions\ldots\ that log distribution has information about both the mean and variance.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item ELBO isn't just about parameter means
    \item It's about the entire distribution (all moments)
    \item Optimising ELBO = making $q(\theta)$ close to $p(\theta|y)$
    \item But mean-field approximation breaks dependencies
\end{itemize}

\subsection*{Insight 9: Conditional vs Unconditional Posteriors}
\textbf{[0:10:29]} ``In Gibbs, you work out conditional posterior distributions. In variational Bayes these are your independent posterior distributions\ldots\ The conditional posterior doesn't take into account the shrinkage.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Gibbs: Cycles through $p(\beta|u, \tau, y)$, $p(u|\beta, \tau, y)$, $p(\tau|\beta, u, y)$ $\rightarrow$ captures dependencies
    \item VB: Assumes $q(\beta)q(u)q(\tau)$ $\rightarrow$ \textbf{ignores} how estimating $\beta$ and $u$ affects degrees of freedom for $\tau$
    \item \textbf{This is the mathematical reason VB underestimates variance of $\tau_u$}
\end{itemize}

\subsection*{Insight 10: Focus on Sample Size Effects}
\textbf{[0:13:50]} ``Emphasise that this sort of model, variational Bayes approximations will do a lot better with larger sample sizes.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Pedagogical message:} VB isn't universally bad
    \item With enough data (large $n$ per group), VB converges to truth
    \item \textbf{Frame VB as data-hungry, not fundamentally broken}
\end{itemize}

\section{Diagnostic Metrics}

\subsection*{Insight 11: Diagnostic Ratio -- Posterior Var / Prior Var of $u$'s}
\textbf{[0:15:49]} ``Plot the posterior variance of the $u$'s over the prior variance\ldots\ When you do badly with $\tau_u$, this ratio will be high. When you do well, this ratio will be low.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{New diagnostic metric:} $\text{Var}_{\text{posterior}}(u_i) / \text{Var}_{\text{prior}}(u_i)$
    \item Ratio $\rightarrow 0$ means posterior is narrow (lots of information learnt)
    \item \textbf{Narrow posteriors for $u$ $\rightarrow$ accurate $\tau_u$ estimation in VB}
    \item This explains the mechanism: VB succeeds when posterior concentrates
\end{itemize}

\subsection*{Insight 12: The Mathematical Connection}
\textbf{[0:17:42]} ``The narrower the posterior distributions for the $u$'s are, the better you will do at getting the posterior for $\tau_u$.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Small sample per group $\rightarrow$ wide posterior for $u_i$ $\rightarrow$ bad $\tau_u$ estimate
    \item Large sample per group $\rightarrow$ narrow posterior for $u_i$ $\rightarrow$ good $\tau_u$ estimate
    \item \textbf{This is because:} VB doesn't account for lost degrees of freedom when estimating $u$'s
    \item Mathematical: $q(\tau_u)$ has $Q/2$ in shape parameter (assumes all $Q$ levels independent)
\end{itemize}

\section{Practical Implementation Decisions}

\subsection*{Insight 13: Speed vs Accuracy Trade-off}
\textbf{[0:19:39]} ``The intention of variational Bayes is it goes fast\ldots\ there's a trade-off there\ldots\ but it's still going to always be faster than MCMC.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Larger samples help VB accuracy
    \item Larger samples slow down both VB and MCMC
    \item \textbf{But VB remains computationally advantageous}
    \item Question becomes: ``How close do you need to be?''
\end{itemize}

\subsection*{Insight 14: Blocking Strategy Matters}
\textbf{[0:21:52]} ``There are two ways to mess up variational Bayes. One is to ignore interdependencies\ldots\ if every single scalar parameter was given its own approximate posterior, that would completely screw it up.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item Your current code: $q(\beta)q(u)q(\tau_u)q(\tau_e)$ $\leftarrow$ \textbf{as blocked as analytically feasible}
    \item Worse alternative: $q(\beta_1)q(\beta_2)\cdots q(u_1)q(u_2)\cdots$ $\leftarrow$ ignores known correlations
    \item \textbf{Your blocking choice is optimal given analytical constraints}
    \item Remaining under-dispersion is inherent to VB, not your implementation
\end{itemize}

\subsection*{Insight 15: $\beta$ and $u$ Estimation is Fine}
\textbf{[0:22:30]} ``It probably doesn't matter very much for $\beta$ and $u$\ldots\ once sample size is about 30--50, you can't tell the difference between a $t$ and a normal distribution.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Don't focus report on $\beta$ estimates} -- VB does well here
    \item $\beta$s have enough data ($N$ observations total)
    \item $u$'s benefit from shrinkage but VB handles them adequately
    \item \textbf{The drama is in $\tau_u$ and $\tau_e$} -- these are hyper-parameters
\end{itemize}

\subsection*{Insight 16: Degrees of Freedom Problem}
\textbf{[0:22:30]} ``Conditional posteriors don't take into consideration the loss of degrees of freedom in estimating some parameters when updating the precisions.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item True posterior: $N - p$ effective observations after estimating $\beta$
    \item VB posterior for $\tau$: \textbf{assumes full $N$} (doesn't subtract $p$)
    \item Few obs per level $\rightarrow$ large proportional loss $\rightarrow$ big error
    \item \textbf{Mathematical root cause of $\tau_u$ under-dispersion}
\end{itemize}

\section{Report Structure and Presentation}

\subsection*{Insight 17: Experimental Plan for Report}
\textbf{[0:25:24]} ``This is going to be the example that goes into the report\ldots\ total number of observations stay unchanged, vary the number of random effect levels.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Report structure:}
    \begin{enumerate}[noitemsep]
        \item Theory section (existing)
        \item Model 3: Random intercept logistic
        \item Show $\tau_u$ posterior for $Q = \{5, 10, 20, 50\}$ observations per level
        \item Demonstrate: VB $\rightarrow$ HMC as observations per level increases
        \item Explain via posterior variance ratio diagnostic
    \end{enumerate}
\end{itemize}

\subsection*{Insight 18: $Q/2$ Parameter}
\textbf{[0:26:28]} ``Our approximate posterior for $\tau_u$ has $Q/2$ in it\ldots\ which is what you get in the conditional posterior, but that means it's not taking out the loss of degrees of freedom.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item VB: $a_n = a_0 + Q/2$ (number of random effect levels)
    \item True: Should be smaller to account for estimating $\beta$ and $u$
    \item \textbf{This is the smoking gun in your equations}
    \item Point this out in report derivations
\end{itemize}

\subsection*{Insight 19: Report Simplification}
\textbf{[0:27:17]} ``Take out the Exact and the Laplace\ldots\ it's just variational Bayes versus Gibbs. Make sure you run multiple chains.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Model 1}: Keep Exact (pedagogical calibration)
    \item \textbf{Model 3}: Only VB vs HMC (no Laplace needed)
    \item Run 4 chains for convergence diagnostics ($\hat{R}$)
    \item Focus plots on \textbf{$\tau_u$ distributions} at different $Q$ levels
\end{itemize}

\subsection*{Insight 20: Don't Vary Priors}
\textbf{[0:28:36]} ``Don't change the priors, because that doesn't help you illustrate what you want to illustrate, which is variational Bayes tends to struggle with shrinkage.''

\textbf{Decision implication:}
\begin{itemize}[noitemsep]
    \item \textbf{Fix priors} across all experiments
    \item Variation in results = VB's handling of data, not prior choice
    \item Stronger priors would confound the message
    \item \textbf{Core message: VB + hierarchical structure + small group sizes = under-dispersion}
\end{itemize}

\section*{Summary of Key Decisions}

\begin{enumerate}
    \item \textbf{Model focus}: Random intercept model (Model 3)
    \item \textbf{Comparison}: VB vs HMC (skip Laplace)
    \item \textbf{Experimental design}: Vary $Q$ (group levels), fix $N$ (total observations)
    \item \textbf{Key metric}: Posterior distributions of $\tau_u$
    \item \textbf{Diagnostic}: $\text{Var}_{\text{post}}(u) / \text{Var}_{\text{prior}}(u)$ ratio
    \item \textbf{Mathematical explanation}: $Q/2$ in shape parameter doesn't account for degrees of freedom loss
    \item \textbf{Pedagogical message}: VB struggles with variance components in hierarchical models when observations per level are small
\end{enumerate}

\vspace{1em}
\noindent\textbf{This is your roadmap for completing the project.}

\end{document}
