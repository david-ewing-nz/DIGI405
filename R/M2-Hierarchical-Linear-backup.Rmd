---
title: 'Variational Bayes: Unified M1/M3 Analysis'
subtitle: '`r paste0(basename(knitr::current_input()), " | Compiled: ", format(Sys.time(), "%Y-%m-%d %H:%M:%S"))`'
header-includes:
   - \usepackage{amsmath}
   - \usepackage{unicode-math}
   - \usepackage{xcolor}
   - \let\bm\symbf
   - \usepackage{tikz}
   - \usetikzlibrary{calc}
   - \usepackage{eso-pic}
   - \usepackage[useregional]{datetime2}
   - '\newcommand{\mymarginlabel}{`r paste0(gsub("_", "\\\\_", basename(knitr::current_input())), " \\textbar{} Compiled: ", format(Sys.time(), "%Y-%m-%d %H:%M:%S"))`}'
   - \AddToShipoutPictureBG{\begin{tikzpicture}[remember picture,overlay]\node[rotate=90, anchor=north] at ($(current page.north west)+(1.4cm,-13cm)$) {\scriptsize\ttfamily \mymarginlabel};\end{tikzpicture}}
output: 
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 3
    keep_tex: false
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(mvtnorm)
library(tidyr)
library(gt)
library(glue)
library(ggplot2)
library(patchwork)
library(png)
library(grid)
set.seed(82171165)
```
\newpage 
```{r parameters, echo=TRUE}
# ============================================================================
# MODEL TYPE SELECTION
# M1: Linear regression with β and σ² (residual variance) 
#     - No random effects, no variance component 

# M3: Hierarchical model with β, u (random effects), τₑ, τᵤ 
#     - Demonstrates variance component under-dispersion
#     - Multi-configuration: Q = 5, 10, 20, 50, 100 groups

model_type <- "M3"  # Fixed to M3 for hierarchical model only

# SHARED PARAMETERS (all configurations)
n <- 300  # Total observations
p <- 3    # Number of fixed effects (beta_0, beta_1, beta_2) - Dr John's setup

# true Parameter Values (Dr John's exact values)
tau_e_true <- 0.5   # Residual precision (variance = 2)
tau_u_true <- 1  # Random effect precision (variance = 1)
beta_true  <- c(0.5, -2, 3)  # Dr John's beta values

# prior Hyperparameters (Dr John's flat priors - no prior information)
alpha_e <- 0
gamma_e <- 0
alpha_u <- 0
gamma_u <- 0

# gibbs Sampler Settings
run_gibbs    <- TRUE   # Set FALSE for quick testing, TRUE for full run
gibbs_iter   <- 5000
gibbs_burnin <- 1000

# display Settings
RENDER_FUNCTIONS <- FALSE  # TRUE to show function code, FALSE to hide

# SCENARIO 1: Q=5 groups (n=60 per group)
q_s1  <- 5
nq_s1 <- 60

# SCENARIO 2: Q=10 groups (n=30 per group)
q_s2  <- 10
nq_s2 <- 30

# SCENARIO 3: Q=20 groups (n=15 per group)
q_s3  <- 20
nq_s3 <- 15

# SCENARIO 4: Q=50 groups (n=6 per group)
q_s4  <- 50
nq_s4 <- 6

# SCENARIO 5: Q=100 groups (n=3 per group)
q_s5  <- 100
nq_s5 <- 3

# ============================================================================
```
\newpage 
```{r function_section, results='asis', include=RENDER_FUNCTIONS}
cat("\\newpage\n\n# Function Definitions\n\n")
```

```{r dr_john_gibbs}
# Dr John Holmes' Gibbs sampler for hierarchical models
# EXACT original from Dr John - NO modifications
normalmm.Gibbs<-function(iter,Z,X,y,burnin,taue_0,tauu_0,Kinv,a.u,b.u,a.e,b.e){
  n   <-length(y) #no. observations
  p   <-dim(X)[2] #no of fixed effect predictors.
  q   <-dim(Z)[2] #no of random effect levels
  tauu<-tauu_0
  taue<-taue_0
  beta0<-rnorm(p)
  u0   <-rnorm(q,0,sd=1/sqrt(tauu))
  
  #Building combined predictor matrix.
  W<-cbind(X,Z)
  WTW <-crossprod(W)
  WTy <-crossprod(W,y)
  library(mvtnorm)
  
  #storing results.
  par <-matrix(0,iter,p+q+2)
  #Calculating log predictive densities
  lppd<-matrix(0,iter,n)
  
  #Create modified identity matrix for joint posterior.
  I0  <-diag(p+q)
  diag(I0)[1:p]<-0
  I0[-c(1:p),-c(1:p)]  <-Kinv
  
  for(i in 1:iter){
    #Conditional posteriors.
    uKinvu <- t(u0)%*%Kinv%*%u0
    uKinvu <-as.numeric(uKinvu)
    tauu <-rgamma(1,a.u+0.5*q,b.u+0.5*uKinvu)
    #Updating component of normal posterior for beta,u
    Prec <-WTW*taue + tauu*I0
    P.var <-solve(Prec)
    P.mean<- P.var%*%WTy*taue
    betau <-rmvnorm(1,mean=P.mean,sigma=P.var)
    betau <-as.numeric(betau)
    err   <- y-W%*%betau
    taue  <-rgamma(1,a.e+0.5*n,b.e+0.5*sum(err^2))
    #storing iterations.
    par[i,]<-c(betau,tauu,taue)
    beta0  <-betau[1:p]
    u0     <-betau[p+1:q]
    lppd[i,]= dnorm(y,mean=as.numeric(W%*%betau),sd=1/sqrt(taue))
  }
  
  lppd      = lppd[-c(1:burnin),]
  lppdest   = sum(log(colMeans(lppd)))        #Estimating lppd for whole dataset.
  pwaic2    = sum(apply(log(lppd),2,FUN=var)) #Estimating effective number of parameters.
  par <-par[-c(1:burnin),]
  colnames(par)<-c(paste('beta',1:p,sep=''),paste('u',1:q,sep=''),'tau_u','tau_e')
  mresult<-list(par,lppdest,pwaic2)
  names(mresult)<-c('par','lppd','pwaic')
  return(mresult)
}
```

```{r dr_john_vb}
# Dr John Holmes' VB algorithm for hierarchical models
# EXACT original from Dr John - NO modifications
VB.mm<-function(epsilon,iter,Kinv,Z,X,y,taue_0,tauu_0,u0,beta0,a.e,g.e,a.u,g.u){
  n<-dim(X)[1]
  p<-dim(X)[2]
  q<-dim(Z)[2]
  W <-cbind(X,Z)
  WTW<-crossprod(W)
  WTY<-crossprod(W,y)
  Kinvall<-matrix(0,p+q,p+q)
  Kinvall[-c(1:p),-c(1:p)]<-Kinv
  
  for(i in 1:iter){
    Vub <-solve(taue_0*WTW+tauu_0*Kinvall) #update Var(b,u)
    ub  <-taue_0*Vub%*%WTY                 #update E(b,u)
    TrKinvub <- sum(diag(Kinvall%*%Vub))
    uKinvub  <- t(ub)%*%Kinvall%*%ub
    tauu    <- (a.u+0.5*q)/(g.u+0.5*as.numeric(uKinvub)+0.5*TrKinvub)
    tauu    <- as.numeric(tauu)
    err     <- y - W%*%ub
    TrWTWub  <- sum(diag(WTW%*%Vub))
    taue    <- (a.e+0.5*n)/(g.e+0.5*sum(err^2)+0.5*TrWTWub)
    taue    <- as.numeric(taue)
    
    if(i > 1){
      diffub  <- sqrt((ub-ub0)^2)/(abs(ub)+0.01)
      diffte <- abs(taue_0-taue)/(taue+0.01)
      difftu <- abs(tauu_0-tauu)/(tauu+0.01)
      diffvub <- sqrt((diag(Vub0) - diag(Vub))^2)/(diag(Vub))
      diff.all<-c(diffub,diffte,difftu,diffvub)
      if(max(diff.all) < epsilon) break
    }
    Vub0 <- Vub;ub0<-ub;taue_0<-taue;tauu_0<-tauu
    #Calculate relative change.
  }
  
  taue.param<-c((a.e+0.5*n),(g.e+0.5*sum(err^2)+0.5*TrWTWub))
  tauu.param<-c((a.u+0.5*q),(g.u+0.5*uKinvub+0.5*TrKinvub))  
  param<-list(ub,Vub,taue.param,tauu.param,i)
  names(param)<-c('betau_mean','betau_var','tau_e','tau_u','iter')
  return(param)
}
```

```{r dr_john_vb_with_history}
# Dr John Holmes' VB algorithm WITH history tracking
# Modified version that tracks E[τₑ], E[τᵤ], and ELBO at each iteration
VB.mm_with_history<-function(epsilon,iter,Kinv,Z,X,y,taue_0,tauu_0,u0,beta0,a.e,g.e,a.u,g.u){
  n<-dim(X)[1]
  p<-dim(X)[2]
  q<-dim(Z)[2]
  W <-cbind(X,Z)
  WTW<-crossprod(W)
  WTY<-crossprod(W,y)
  Kinvall<-matrix(0,p+q,p+q)
  Kinvall[-c(1:p),-c(1:p)]<-Kinv
  
  # Initialize history storage
  E_tau_e_history <- numeric(iter)
  E_tau_u_history <- numeric(iter)
  elbo_history <- numeric(iter)
  
  for(i in 1:iter){
    Vub <-solve(taue_0*WTW+tauu_0*Kinvall) #update Var(b,u)
    ub  <-taue_0*Vub%*%WTY                 #update E(b,u)
    TrKinvub <- sum(diag(Kinvall%*%Vub))
    uKinvub  <- t(ub)%*%Kinvall%*%ub
    tauu    <- (a.u+0.5*q)/(g.u+0.5*as.numeric(uKinvub)+0.5*TrKinvub)
    tauu    <- as.numeric(tauu)
    err     <- y - W%*%ub
    TrWTWub  <- sum(diag(WTW%*%Vub))
    taue    <- (a.e+0.5*n)/(g.e+0.5*sum(err^2)+0.5*TrWTWub)
    taue    <- as.numeric(taue)
    
    # Store history
    E_tau_e_history[i] <- taue
    E_tau_u_history[i] <- tauu
    
    # Calculate ELBO (simplified version for monitoring convergence)
    elbo <- -0.5 * n * log(2*pi) + 0.5 * n * (digamma(a.e+0.5*n) - log(g.e+0.5*sum(err^2)+0.5*TrWTWub))
    elbo <- elbo - 0.5 * q * log(2*pi) + 0.5 * q * (digamma(a.u+0.5*q) - log(g.u+0.5*as.numeric(uKinvub)+0.5*TrKinvub))
    elbo_history[i] <- elbo
    
    if(i > 1){
      diffub  <- sqrt((ub-ub0)^2)/(abs(ub)+0.01)
      diffte <- abs(taue_0-taue)/(taue+0.01)
      difftu <- abs(tauu_0-tauu)/(tauu+0.01)
      diffvub <- sqrt((diag(Vub0) - diag(Vub))^2)/(diag(Vub))
      diff.all<-c(diffub,diffte,difftu,diffvub)
      if(max(diff.all) < epsilon) break
    }
    Vub0 <- Vub;ub0<-ub;taue_0<-taue;tauu_0<-tauu
  }
  
  # Trim history to actual iterations
  E_tau_e_history <- E_tau_e_history[1:i]
  E_tau_u_history <- E_tau_u_history[1:i]
  elbo_history <- elbo_history[1:i]
  
  taue.param<-c((a.e+0.5*n),(g.e+0.5*sum(err^2)+0.5*TrWTWub))
  tauu.param<-c((a.u+0.5*q),(g.u+0.5*uKinvub+0.5*TrKinvub))  
  param<-list(ub,Vub,taue.param,tauu.param,i,E_tau_e_history,E_tau_u_history,elbo_history)
  names(param)<-c('betau_mean','betau_var','tau_e','tau_u','iter','E_tau_e_history','E_tau_u_history','elbo_history')
  return(param)
}
```

```{r run_gibbs_sampler, include=RENDER_FUNCTIONS}
# full Gibbs sampler (MCMC gold standard)
# - M1: β | τₑ, y  and  τₑ | β, y
# - M3: (β,u) | τₑ,τᵤ,y  and  τₑ,τᵤ | (β,u),y
# - Returns post-burnin samples for posterior inference
# Following Dr John's approach: run 3 chains with different initialisations and combine
run_gibbs_sampler <- function(X, Z, y, p, q, n, alpha_e, gamma_e, alpha_u, gamma_u,
                               n_iter = 5000, n_burnin = 1000,
                               init_taue = NULL, init_tauu = NULL) {
  
  set.seed(82171165)
  
  # M3: Use Dr John Holmes' Gibbs sampler with 3 different initialisations
    K     <- diag(q)
    K_inv <- solve(K)
    
    # Dr John's three initialisation strategies (matching his code exactly)
    init_configs <- list(
      list(tau_e = 3,   tau_u = 0.5),  # test1: low tau_u guess
      list(tau_e = 0.5, tau_u = 3),    # test2: high tau_u guess
      list(tau_e = 5,   tau_u = 5)     # test3: both high
    )
    
    all_samples <- list()
    
    for (init_idx in 1:3) {
      init_taue_val <- init_configs[[init_idx]]$tau_e
      init_tauu_val <- init_configs[[init_idx]]$tau_u
      
      # call Dr John's function
      gibbs_result <- normalmm.Gibbs(
        iter     = n_iter,
        Z        = Z,
        X        = X,
        y        = y,
        burnin   = n_burnin,
        taue_0   = init_taue_val,
        tauu_0   = init_tauu_val,
        Kinv     = K_inv,
        a.u      = alpha_u,
        b.u      = gamma_u,
        a.e      = alpha_e,
        b.e      = gamma_e
      )
      
      # reformat output to match expected structure
      # Dr John's colnames: beta1, beta2, ..., u1, u2, ..., tau_u, tau_e
      # Expected colnames: beta0, beta1, ..., u1, u2, ..., tau_e, tau_u
      samples_chain <- gibbs_result$par
      
      # reorder columns: move tau_e before tau_u
      n_cols <- ncol(samples_chain)
      tau_e_col <- samples_chain[, n_cols]      # Last column is tau_e
      tau_u_col <- samples_chain[, n_cols - 1]  # Second-to-last is tau_u
      samples_chain <- cbind(samples_chain[, 1:(n_cols-2)], tau_e_col, tau_u_col)
      
      # fix column names: beta1→beta0, beta2→beta1, etc.
      beta_names <- paste0("beta", 0:(p-1))
      u_names <- paste0("u", 1:q)
      colnames(samples_chain) <- c(beta_names, u_names, "tau_e", "tau_u")
      
      all_samples[[init_idx]] <- samples_chain
    }
    
    # combine all three chains (matching Dr John's approach)
    samples <- do.call(rbind, all_samples)
  
  return(samples)
}
```

```{r plot_vb_posteriors, include=RENDER_FUNCTIONS}
# source simplified VB vs Gibbs plotting function
# - Shows VB vs Gibbs comparison (no Exact or Laplace)
# - Displays SD ratios: VB/Gibbs
# - Demonstrates under-dispersion for variance components

# source all plotting functions (copied to same directory by knit script)
source("plot_vb_posteriors_gibbs_only.R")
source("plot_beta_panel.R")
source("plot_u_panel.R")
source("plot_tau_panel.R")
```

\newpage

```{r run_vb_algorithm, include=RENDER_FUNCTIONS}
# mean-field VB with coordinate ascent
# - Updates: q(β,u), q(τₑ), q(τᵤ) iteratively
# - Tracks ELBO for convergence monitoring
# - Returns variational posterior parameters
run_vb_algorithm <- function(X, Z, y, K, p, q, n, alpha_e, gamma_e, alpha_u, gamma_u, 
                              model_type = "M3", max_iter = 100, tol = 1e-5) {
  
  # for M3, use Dr John Holmes' VB algorithm
  if (model_type == "M3") {
    K_inv <- solve(K)
    
    # call Dr John's VB.mm_with_history function
    # handle flat priors: when alpha=0, gamma=0, initialize with 1.0
    init_taue <- if (alpha_e > 0 && gamma_e > 0) alpha_e / gamma_e else 1.0
    init_tauu <- if (alpha_u > 0 && gamma_u > 0) alpha_u / gamma_u else 1.0
    
    vb_result <- VB.mm_with_history(
      epsilon = tol,
      iter    = max_iter,
      Kinv    = K_inv,
      Z       = Z,
      X       = X,
      y       = y,
      taue_0  = init_taue,
      tauu_0  = init_tauu,
      u0      = rep(0, q),
      beta0   = rep(0, p),
      a.e     = alpha_e,
      g.e     = gamma_e,
      a.u     = alpha_u,
      g.u     = gamma_u
    )
    
    # reformat output to match expected structure
    betau       <- vb_result$betau_mean
    Sigma_betau <- vb_result$betau_var
    
    mu_beta    <- betau[1:p]
    mu_u       <- betau[(p+1):(p+q)]
    Sigma_beta <- Sigma_betau[1:p, 1:p]
    Sigma_uu   <- Sigma_betau[(p+1):(p+q), (p+1):(p+q)]
    
    # extract precision parameters (a, b) for Gamma distributions
    a_e_new <- vb_result$tau_e[1]
    b_e_new <- vb_result$tau_e[2]
    a_u_new <- vb_result$tau_u[1]
    b_u_new <- vb_result$tau_u[2]
    
    # compute expectations
    E_tau_e <- a_e_new / b_e_new
    E_tau_u <- a_u_new / b_u_new
    
    # Extract histories from VB.mm_with_history result
    E_tau_e_history <- vb_result$E_tau_e_history
    E_tau_u_history <- vb_result$E_tau_u_history
    elbo_history    <- vb_result$elbo_history
    
    # return in expected format
    return(list(
      mu_betau        = betau,
      Sigma_betau     = Sigma_betau,
      mu_beta         = mu_beta,
      mu_u            = mu_u,
      Sigma_beta      = Sigma_beta,
      Sigma_uu        = Sigma_uu,
      E_tau_e         = E_tau_e,
      E_tau_u         = E_tau_u,
      a_e_new         = a_e_new,
      b_e_new         = b_e_new,
      a_u_new         = a_u_new,
      b_u_new         = b_u_new,
      E_tau_e_history = E_tau_e_history,
      E_tau_u_history = E_tau_u_history,
      elbo_history    = elbo_history
    ))
  }
  
  # If VB.mm_with_history didn't converge, manual setup below
  K_inv          <- solve(K)
  penalty_matrix <- rbind(
    cbind(matrix(0, p, p), matrix(0, p, q)),
    cbind(matrix(0, q, p), K_inv)
  )
  XZ      <- cbind(X, Z)
  XZ_t_XZ <- t(XZ) %*% XZ
  XZ_t_y  <- t(XZ) %*% y
  
  E_tau_e <- alpha_e / gamma_e
  E_tau_u <- alpha_u / gamma_u
  
  E_tau_e_history <- numeric(max_iter)
  E_tau_u_history <- numeric(max_iter)
  elbo_history    <- numeric(max_iter)
  
  mu_betau_old    <- NA
  Sigma_betau_old <- NA
  
  for (iter in 1:max_iter) {
    
    precision_betau <- E_tau_e * XZ_t_XZ + E_tau_u * penalty_matrix
    Sigma_betau     <- solve(precision_betau)
    mu_betau        <- E_tau_e * Sigma_betau %*% XZ_t_y
    
    mu_beta  <- mu_betau[1:p]
    Sigma_beta <- Sigma_betau[1:p, 1:p]
    mu_u     <- mu_betau[(p+1):(p+q)]
    Sigma_uu <- Sigma_betau[(p+1):(p+q), (p+1):(p+q)]
    
    residuals <- y - XZ %*% mu_betau
    SSR       <- sum(residuals^2)
    trace_e   <- sum(diag(XZ_t_XZ %*% Sigma_betau))
    
    a_e_new <- alpha_e + n/2
    b_e_new <- gamma_e + 0.5 * (SSR + trace_e)
    
    E_tau_e_old <- E_tau_e
    E_tau_e     <- a_e_new / b_e_new
    
    quad_form <- as.numeric(t(mu_u) %*% K_inv %*% mu_u)
    trace_u   <- sum(diag(K_inv %*% Sigma_uu))
    a_u_new <- alpha_u + q/2
    b_u_new <- gamma_u + 0.5 * (quad_form + trace_u)
    E_tau_u_old <- E_tau_u
    E_tau_u     <- a_u_new / b_u_new
    
    E_log_p_y <- -0.5*n*log(2*pi) +  # Expected log-likelihood (Gaussian with precision τₑ)
                 0.5*n*(digamma(a_e_new) - log(b_e_new)) - 
                 0.5*E_tau_e*(SSR + trace_e)
    
    E_log_p_betau <- -0.5*q*log(2*pi) +  # Expected log-prior for β and u (random effects with τᵤ)
                     0.5*q*(digamma(a_u_new) - log(b_u_new)) - 
                     0.5*E_tau_u*(quad_form + trace_u)
    E_log_p_tau_u <- alpha_u*log(gamma_u) - lgamma(alpha_u) +  # Expected log-prior for τᵤ (Gamma prior)
                     (alpha_u-1)*(digamma(a_u_new) - log(b_u_new)) - 
                     gamma_u*E_tau_u
    entropy_tau_u <- a_u_new - log(b_u_new) + lgamma(a_u_new) +  # Entropy of q(τᵤ) ~ Gamma(aᵤ, bᵤ)
                     (1-a_u_new)*digamma(a_u_new)
    
    E_log_p_tau_e <- alpha_e*log(gamma_e) - lgamma(alpha_e) +  # Expected log-prior for τₑ (Gamma prior)
                     (alpha_e-1)*(digamma(a_e_new) - log(b_e_new)) - 
                     gamma_e*E_tau_e
    
    dim_param <- p + q
    entropy_betau <- 0.5*determinant(Sigma_betau, logarithm=TRUE)$modulus +  # Entropy of q(β,u)
                     0.5*dim_param*(1 + log(2*pi))
    
    entropy_tau_e <- a_e_new - log(b_e_new) + lgamma(a_e_new) +  # Entropy of q(τₑ) ~ Gamma(aₑ, bₑ)
                     (1-a_e_new)*digamma(a_e_new)
    
    elbo <- E_log_p_y + E_log_p_betau + E_log_p_tau_e + E_log_p_tau_u + 
            entropy_betau + entropy_tau_e + entropy_tau_u
    
    E_tau_e_history[iter] <- E_tau_e
    E_tau_u_history[iter] <- E_tau_u
    elbo_history[iter]    <- elbo
    
    if (iter > 1) {
      diff_betau <- sqrt((mu_betau - mu_betau_old)^2) / (abs(mu_betau) + 0.01)
      diff_tau_e <- abs(E_tau_e - E_tau_e_old) / (E_tau_e + 0.01)
      diff_tau_u <- abs(E_tau_u - E_tau_u_old) / (E_tau_u + 0.01)
      diff_Sigma <- sqrt((diag(Sigma_betau) - diag(Sigma_betau_old))^2) / 
                    (diag(Sigma_betau) + 0.01)
      
      diff_all <- c(diff_betau, diff_tau_e, diff_tau_u, diff_Sigma)
      
      if (max(diff_all) < tol) {
        cat("Converged at iteration", iter, "\n")
        cat("Max relative change:", sprintf("%.2e", max(diff_all)), "\n")
        E_tau_e_history <- E_tau_e_history[1:iter]
        E_tau_u_history <- E_tau_u_history[1:iter]
        elbo_history    <- elbo_history[1:iter]
        break
      }
    }
    
    mu_betau_old    <- mu_betau
    Sigma_betau_old <- Sigma_betau
  }
  
  list(
    mu_betau        = mu_betau,
    Sigma_betau     = Sigma_betau,
    mu_beta         = mu_beta,
    mu_u            = mu_u,
    Sigma_beta      = Sigma_beta,
    Sigma_uu        = Sigma_uu,
    E_tau_e         = E_tau_e,
    E_tau_u         = E_tau_u,
    a_e_new         = a_e_new,
    b_e_new         = b_e_new,
    a_u_new         = a_u_new,
    b_u_new         = b_u_new,
    E_tau_e_history = E_tau_e_history,
    E_tau_u_history = E_tau_u_history,
    elbo_history    = elbo_history
  )
}
```

```{r plot_convergence, include=RENDER_FUNCTIONS}
# VB parameter convergence diagnostic
# - Plots E[τₑ] and E[τᵤ] vs iteration
# - Shows convergence to true values
# - Helps identify convergence issues
plot_convergence <- function(results, scenario_name, tau_e_true, tau_u_true, model_type = "M3") {
  
  # Check if history data is available
  if (is.null(results$E_tau_e_history) || length(results$E_tau_e_history) == 0) {
    # No history data - Dr John's functions don't return history
    return(ggplot() + 
             annotate("text", x = 0.5, y = 0.5, 
                     label = "Convergence history not available\n(Dr John's original functions)", 
                     size = 6) +
             theme_void())
  }
  
  # tau_e convergence plot
  df_e <- data.frame(
    iteration = 1:length(results$E_tau_e_history),
    value     = results$E_tau_e_history
  )
  
  p_e <- ggplot(df_e, aes(x = iteration, y = value)) +
    geom_line(color = "blue", linewidth = 1.2) +
    geom_hline(yintercept = tau_e_true, color = "red", linetype = "dashed", linewidth = 1.2) +
    labs(
      x     = "Iteration",
      y     = expression(E*"["*tau[e]*"]"),
      title = glue("{scenario_name}: Convergence of E[tau_e]")
    ) +
    theme_minimal() +
    theme(
      plot.title       = element_text(hjust = 0.5),
      panel.grid.minor = element_blank()
    )
  
  if (model_type == "M3") {
    # tau_u convergence plot
    df_u <- data.frame(
      iteration = 1:length(results$E_tau_u_history),
      value     = results$E_tau_u_history
    )
    
    p_u <- ggplot(df_u, aes(x = iteration, y = value)) +
      geom_line(color = "blue", linewidth = 1.2) +
      geom_hline(yintercept = tau_u_true, color = "red", linetype = "dashed", linewidth = 1.2) +
      labs(
        x     = "Iteration",
        y     = expression(E*"["*tau[u]*"]"),
        title = glue("{scenario_name}: Convergence of E[tau_u]")
      ) +
      theme_minimal() +
      theme(
        plot.title       = element_text(hjust = 0.5),
        panel.grid.minor = element_blank()
      )
    
    # combine plots side by side
    combined_plot <- p_e + p_u
    return(combined_plot)
  } else {
    return(p_e)
  }
}
```

```{r plot_elbo, include=RENDER_FUNCTIONS}
# ELBO trajectory plot
# - Evidence Lower BOund over iterations
# - Should be monotonically increasing
# - Flattening indicates convergence
plot_elbo <- function(results, scenario_name) {
  # Check if history data is available
  if (is.null(results$elbo_history) || length(results$elbo_history) == 0) {
    # No ELBO history - Dr John's functions don't return this
    return(ggplot() + 
             annotate("text", x = 0.5, y = 0.5, 
                     label = "ELBO history not available\n(Dr John's original functions)", 
                     size = 6) +
             theme_void())
  }
  
  df <- data.frame(
    iteration = 1:length(results$elbo_history),
    elbo      = results$elbo_history
  )
  
  p_elbo <- ggplot(df, aes(x = iteration, y = elbo)) +
    geom_line(color = "darkgreen", linewidth = 1.2) +
    labs(
      x     = "Iteration",
      y     = "ELBO",
      title = glue("{scenario_name}: ELBO Convergence")
    ) +
    theme_minimal() +
    theme(
      plot.title       = element_text(hjust = 0.5),
      panel.grid.major = element_line(color = "gray90"),
      panel.grid.minor = element_blank()
    )
  
  return(p_elbo)
}
```

\newpage

# scenario 1: Conditional on Model Type

```{r scenario1_data}
cat(glue("\n=== Scenario 1: Q={q_s1} groups (n={nq_s1} per group) ===\n"))

X_s1 <- cbind(1, matrix(rnorm(n*(p-1)), nrow=n, ncol=p-1))

if (model_type == "M3") {
  # Dr John's method: generate then standardize
  u_true_s1 <- rnorm(q_s1, 0, 1)
  u_true_s1 <- scale(u_true_s1)
  Z_s1 <- table(1:n, rep(1:q_s1, n/q_s1))  # Dr John's method
  K_s1 <- diag(q_s1)
  linear_predictor_s1 <- X_s1 %*% beta_true + Z_s1 %*% u_true_s1
} else {
  u_true_s1 <- NULL
  Z_s1 <- matrix(0, nrow=n, ncol=1)
  K_s1 <- matrix(1)
  linear_predictor_s1 <- X_s1 %*% beta_true
}

# Dr John's method: hardcoded sd = sqrt(2)
residuals_true_s1 <- rnorm(n, 0, sqrt(2))
y_s1 <- as.vector(linear_predictor_s1 + residuals_true_s1)
```

```{r temp_barplot, include=FALSE}
# generate temporary bar chart for timestamp tracking
temp_data <- data.frame(
  category = c("A", "B"),
  value    = c(2, 5)
)

temp_plot <- ggplot(temp_data, aes(x = category, y = value, fill = category)) +
  geom_col(width = 0.6) +
  labs(title = "Simple Bar Chart", x = "Category", y = "Value") +
  theme_minimal() +
  theme(legend.position = "none")

ggsave("../figs/temp_barplot.png", temp_plot, width = 6, height = 4, dpi = 300)
```

```{r scenario1_vb}
scenario_name <- if (model_type == "M3") glue("SCENARIO 1: {q_s1} levels ({nq_s1} obs each)") else "SCENARIO 1: Linear Regression"
cat(glue("\n=== {scenario_name} ===\n"))
results_s1 <- run_vb_algorithm(
  X          = X_s1,
  Z          = Z_s1,
  y          = y_s1,
  K          = K_s1,
  p          = p,
  q          = q_s1,
  n          = n,
  alpha_e    = alpha_e,
  gamma_e    = gamma_e,
  alpha_u    = alpha_u,
  gamma_u    = gamma_u
)
```





```{r scenario1_gibbs}
if (run_gibbs) {
  cat("\nRunning Gibbs sampler...\n")
  gibbs_s1 <- run_gibbs_sampler(
    X          = X_s1,
    Z          = Z_s1,
    y          = y_s1,
    p          = p,
    q          = q_s1,
    n          = n,
    alpha_e    = alpha_e,
    gamma_e    = gamma_e,
    alpha_u    = alpha_u,
    gamma_u    = gamma_u,
    n_iter     = gibbs_iter,
    n_burnin   = gibbs_burnin
  )
  
  cat("Gibbs posterior means:\n")
  cat("beta:", colMeans(gibbs_s1[, 1:p]), "\n")
  cat("tau_e:", mean(gibbs_s1[, "tau_e"]), "\n")
  if (model_type == "M3") {
    cat("tau_u:", mean(gibbs_s1[, "tau_u"]), "\n")
  }
  
  gibbs_tau_e_s1 <- gibbs_s1[, "tau_e"]
  gibbs_tau_u_s1 <- if (model_type == "M3") gibbs_s1[, "tau_u"] else NULL
} else {
  gibbs_s1 <- NULL
  gibbs_tau_e_s1 <- NULL
  gibbs_tau_u_s1 <- NULL
}
```

```{r scenario1_convergence, echo=FALSE, fig.width=12, fig.height=6}
conv_plot_s1 <- plot_convergence(results_s1, scenario_name, tau_e_true, tau_u_true, model_type)

plot_width <- if (model_type == "M1") 6 else 12
ggsave(
  filename = "../figs/s1_convergence.png",
  plot     = conv_plot_s1,
  width    = plot_width,
  height   = 6,
  dpi      = 300
)

img_conv <- readPNG("../figs/s1_convergence.png")
grid.newpage()
grid.raster(img_conv)
```

\newpage

```{r scenario1_elbo, echo=FALSE, fig.height=5, fig.width=8}
elbo_plot_s1 <- plot_elbo(results_s1, scenario_name)

ggsave(
  filename = "../figs/s1_elbo.png",
  plot     = elbo_plot_s1,
  width    = 8,
  height   = 5,
  dpi      = 300
)

img_elbo <- readPNG("../figs/s1_elbo.png")
grid.newpage()
grid.raster(img_elbo)
```

```{r scenario1_ggplots_allinone, echo=FALSE, fig.width=8, fig.height=11}
# Approach 1: All-in-one function (existing monolithic approach)
combined_plot_s1_allinone <- plot_vb_posteriors(
  mu_beta          = results_s1$mu_betau,
  Sigma_betau      = results_s1$Sigma_betau,
  gibbs_samples    = gibbs_s1,
  p                = p,
  q                = q_s1,
  beta_true        = beta_true,
  u_true           = u_true_s1,
  tau_e_true       = tau_e_true,
  tau_u_true       = tau_u_true,
  E_tau_e          = results_s1$E_tau_e,
  E_tau_u          = results_s1$E_tau_u,
  a_e_new          = results_s1$a_e_new,
  b_e_new          = results_s1$b_e_new,
  a_u_new          = results_s1$a_u_new,
  b_u_new          = results_s1$b_u_new,
  gibbs_tau_e      = gibbs_tau_e_s1,
  gibbs_tau_u      = gibbs_tau_u_s1,
  run_gibbs        = run_gibbs,
  model_type       = model_type
)

total_plots_s1 <- p + 4
n_rows_s1 <- ceiling(total_plots_s1 / 2)

plot_name_s1 <- "vb_Q5_8Panel.png"
ggsave(
  filename = glue("../figs/{plot_name_s1}"),
  plot     = combined_plot_s1_allinone,
  width    = 20,
  height   = 5 * n_rows_s1,
  dpi      = 300
)

cat(glue("M3: {total_plots_s1}-panel ggplot saved for Scenario 1\n"))

img_s1 <- readPNG(glue("../figs/{plot_name_s1}"))
grid.newpage()
grid.raster(img_s1)
```

# scenario 2: Conditional on Model Type (M3 only)

```{r scenario2_data}
if (model_type == "M3") {
  cat(glue("\n=== Scenario 2: Q={q_s2} groups (n={nq_s2} per group) ===\n"))
  
  # Dr John's method: generate then standardize
  u_true_s2 <- rnorm(q_s2, 0, 1)
  u_true_s2 <- scale(u_true_s2)
  
  X_s2 <- cbind(1, matrix(rnorm(n*(p-1)), nrow=n, ncol=p-1))
  Z_s2 <- table(1:n, rep(1:q_s2, n/q_s2))  # Dr John's method
  K_s2 <- diag(q_s2)
  
  linear_predictor_s2 <- X_s2 %*% beta_true + Z_s2 %*% u_true_s2
  residuals_true_s2   <- rnorm(n, 0, sqrt(2))  # Dr John's method: hardcoded
  y_s2 <- as.vector(linear_predictor_s2 + residuals_true_s2)
} else {
  cat("\nScenario 2 skipped (M3 only)\n")
}
```

```{r scenario2_vb, eval=(model_type=="M3")}
results_s2 <- run_vb_algorithm(
  X          = X_s2,
  Z          = Z_s2,
  y          = y_s2,
  K          = K_s2,
  p          = p,
  q          = q_s2,
  n          = n,
  alpha_e    = alpha_e,
  gamma_e    = gamma_e,
  alpha_u    = alpha_u,
  gamma_u    = gamma_u
)
```





```{r scenario2_gibbs, eval=(model_type=="M3")}
if (run_gibbs) {
  cat("\nRunning Gibbs sampler...\n")
  gibbs_s2 <- run_gibbs_sampler(
    X          = X_s2,
    Z          = Z_s2,
    y          = y_s2,
    p          = p,
    q          = q_s2,
    n          = n,
    alpha_e    = alpha_e,
    gamma_e    = gamma_e,
    alpha_u    = alpha_u,
    gamma_u    = gamma_u,
    n_iter     = gibbs_iter,
    n_burnin   = gibbs_burnin
  )
  
  cat("Gibbs posterior means:\n")
  cat("beta:", colMeans(gibbs_s2[, 1:p]), "\n")
  cat("tau_e:", mean(gibbs_s2[, "tau_e"]), "\n")
  cat("tau_u:", mean(gibbs_s2[, "tau_u"]), "\n")
  
  gibbs_tau_e_s2 <- gibbs_s2[, "tau_e"]
  gibbs_tau_u_s2 <- gibbs_s2[, "tau_u"]
} else {
  gibbs_s2 <- NULL
  gibbs_tau_e_s2 <- NULL
  gibbs_tau_u_s2 <- NULL
}
```

```{r scenario2_convergence, echo=FALSE, fig.width=12, fig.height=6, eval=(model_type=="M3")}
conv_plot_s2 <- plot_convergence(results_s2, "Scenario 2", tau_e_true, tau_u_true, model_type)

ggsave(
  filename = "../figs/s2_convergence.png",
  plot     = conv_plot_s2,
  width    = 12,
  height   = 6,
  dpi      = 300
)

img_conv2 <- readPNG("../figs/s2_convergence.png")
grid.newpage()
grid.raster(img_conv2)
```

```{r scenario2_elbo, echo=FALSE, fig.height=5, fig.width=8, eval=(model_type=="M3")}
elbo_plot_s2 <- plot_elbo(results_s2, "Scenario 2")

ggsave(
  filename = "../figs/s2_elbo.png",
  plot     = elbo_plot_s2,
  width    = 8,
  height   = 5,
  dpi      = 300
)

img_elbo2 <- readPNG("../figs/s2_elbo.png")
grid.newpage()
grid.raster(img_elbo2)
```

```{r scenario2_ggplots_allinone, echo=FALSE, fig.width=8, fig.height=11, eval=(model_type=="M3")}
# Approach 1: All-in-one function (existing monolithic approach)
combined_plot_s2_allinone <- plot_vb_posteriors(
  mu_beta          = results_s2$mu_betau,
  Sigma_betau      = results_s2$Sigma_betau,
  gibbs_samples    = gibbs_s2,
  p                = p,
  q                = q_s2,
  beta_true        = beta_true,
  u_true           = u_true_s2,
  tau_e_true       = tau_e_true,
  tau_u_true       = tau_u_true,
  E_tau_e          = results_s2$E_tau_e,
  E_tau_u          = results_s2$E_tau_u,
  a_e_new          = results_s2$a_e_new,
  b_e_new          = results_s2$b_e_new,
  a_u_new          = results_s2$a_u_new,
  b_u_new          = results_s2$b_u_new,
  gibbs_tau_e      = gibbs_tau_e_s2,
  gibbs_tau_u      = gibbs_tau_u_s2,
  run_gibbs        = run_gibbs,
  model_type       = model_type
)

total_plots_s2 <- p + 4
n_rows_s2 <- ceiling(total_plots_s2 / 2)

ggsave(
  filename = "../figs/vb_Q50_8Panel.png",
  plot     = combined_plot_s2_allinone,
  width    = 20,
  height   = 5 * n_rows_s2,
  dpi      = 300
)

cat("M3: 8-panel ggplot saved for Scenario 2\n")

img_s2 <- readPNG("../figs/vb_Q50_8Panel.png")
grid.newpage()
grid.raster(img_s2)
```

# comparison Between Scenarios (M3 only)

```{r comparison_table, eval=(model_type=="M3")}
comparison_df <- data.frame(
  Parameter   = c("E[tau_e]", "E[tau_u]", "sigma^2_e", "sigma^2_u"),
  True_Value  = c(tau_e_true, tau_u_true, 1/tau_e_true, 1/tau_u_true),
  Scenario_30 = c(results_s1$E_tau_e, results_s1$E_tau_u, 
                  1/results_s1$E_tau_e, 1/results_s1$E_tau_u),
  Scenario_6  = c(results_s2$E_tau_e, results_s2$E_tau_u, 
                  1/results_s2$E_tau_e, 1/results_s2$E_tau_u)
)

print(comparison_df)

cat("\nUnder-dispersion in tau_u estimates:\n")
cat("Q=5:  VB tau_u =", round(results_s1$E_tau_u, 4), 
    "vs True =", tau_u_true, 
    "(ratio:", round(results_s1$E_tau_u / tau_u_true, 4), ")\n")
cat("Q=50: VB tau_u =", round(results_s2$E_tau_u, 4), 
    "vs True =", tau_u_true, 
    "(ratio:", round(results_s2$E_tau_u / tau_u_true, 4), ")\n")
```

# sample Size Effects on τ_u (Multi-Configuration Analysis)

```{r tau_u_sample_size_analysis, eval=(model_type=="M3")}
# experimental design: Fix N=300, vary Q to show sample size per group effect
# Following Dr John's guidance (Meeting 16 Jan 2026)
# Q = 5 → 60 obs/group (rich data)
# Q = 10 → 30 obs/group  
# Q = 20 → 15 obs/group
# Q = 50 → 6 obs/group (sparse data)

cat("\n========================================\n")
cat("Multi-Configuration τ_u Analysis\n")
cat("========================================\n")

group_configs <- list(
  list(q = 5,   nq = 60, label = "Q=5 (n=60 per group)"),
  list(q = 10,  nq = 30, label = "Q=10 (n=30 per group)"),
  list(q = 20,  nq = 15, label = "Q=20 (n=15 per group)"),
  list(q = 50,  nq = 6,  label = "Q=50 (n=6 per group)"),
  list(q = 100, nq = 3,  label = "Q=100 (n=3 per group)")
)

results_multi <- list()

for (i in seq_along(group_configs)) {
  config <- group_configs[[i]]
  cat("\n--- Running:", config$label, "---\n")
  
  # generate data using Dr John's exact method
  q_temp <- config$q
  nq_temp <- config$nq
  
  # Dr John's method: generate then standardize
  u_true_temp <- rnorm(q_temp, 0, 1)
  u_true_temp <- scale(u_true_temp)
  
  # Dr John's method: table() for incidence matrix
  Z_temp <- table(1:n, rep(1:q_temp, n/q_temp))
  
  # Dr John's method: simple X matrix (no correlation)
  X_temp <- cbind(1, matrix(rnorm(n*(p-1)), n, p-1))
  
  # Dr John's method: hardcoded residual sd = sqrt(2)
  eta_temp <- X_temp %*% beta_true + Z_temp %*% u_true_temp
  y_temp <- as.vector(eta_temp + rnorm(n, 0, sqrt(2)))
  
  # Covariance matrix for random effects
  K_temp <- diag(q_temp)
  
  # Run VB
  vb_result <- run_vb_algorithm(
    X       = X_temp,
    Z       = Z_temp,
    y       = y_temp,
    K       = K_temp,
    p       = p,
    q       = q_temp,
    n       = n,
    alpha_e = alpha_e,
    gamma_e = gamma_e,
    alpha_u = alpha_u,
    gamma_u = gamma_u,
    tol     = 1e-4,
    max_iter = 500
  )
  
  # Run Gibbs 3 times with different inits (Dr John's convergence check)
  if (run_gibbs) {
    cat("Running Gibbs with 3 different initial values...\n")
    
    # Run 1: taue_0=3, tauu_0=0.5
    gibbs_run1 <- run_gibbs_sampler(
      X        = X_temp,
      Z        = Z_temp,
      y        = y_temp,
      p        = p,
      q        = q_temp,
      n        = n,
      alpha_e  = alpha_e,
      gamma_e  = gamma_e,
      alpha_u  = alpha_u,
      gamma_u  = gamma_u,
      n_iter   = gibbs_iter,
      n_burnin = gibbs_burnin,
      init_taue = 3,
      init_tauu = 0.5
    )
    
    # Run 2: taue_0=0.5, tauu_0=3
    gibbs_run2 <- run_gibbs_sampler(
      X        = X_temp,
      Z        = Z_temp,
      y        = y_temp,
      p        = p,
      q        = q_temp,
      n        = n,
      alpha_e  = alpha_e,
      gamma_e  = gamma_e,
      alpha_u  = alpha_u,
      gamma_u  = gamma_u,
      n_iter   = gibbs_iter,
      n_burnin = gibbs_burnin,
      init_taue = 0.5,
      init_tauu = 3
    )
    
    # Run 3: taue_0=5, tauu_0=5
    gibbs_run3 <- run_gibbs_sampler(
      X        = X_temp,
      Z        = Z_temp,
      y        = y_temp,
      p        = p,
      q        = q_temp,
      n        = n,
      alpha_e  = alpha_e,
      gamma_e  = gamma_e,
      alpha_u  = alpha_u,
      gamma_u  = gamma_u,
      n_iter   = gibbs_iter,
      n_burnin = gibbs_burnin,
      init_taue = 5,
      init_tauu = 5
    )
    
    # Combine all 3 runs (Dr John's method)
    gibbs_result <- rbind(gibbs_run1, gibbs_run2, gibbs_run3)
    cat("Combined", nrow(gibbs_result), "samples from 3 Gibbs runs\n")
  } else {
    gibbs_result <- NULL
  }
  
  # Store results
  results_multi[[i]] <- list(
    config = config,
    vb     = vb_result,
    gibbs  = gibbs_result
  )
  
  cat("VB E[tau_u]:", round(vb_result$E_tau_u, 4), "\n")
  if (!is.null(gibbs_result)) {
    cat("HMC E[tau_u]:", round(mean(gibbs_result[, "tau_u"]), 4), "\n")
  }
}

cat("\n========================================\n")
```

```{r comparison_convergence, fig.height=6, fig.width=10, eval=(model_type=="M3")}
# Check if history data is available
if (!is.null(results_multi[[1]]$vb$E_tau_u_history) && length(results_multi[[1]]$vb$E_tau_u_history) > 0) {
  par(mfrow = c(1, 2))
  
  # E[tau_u] convergence for all configurations
  max_len_tau <- max(sapply(results_multi, function(r) length(r$vb$E_tau_u_history)))
  
  plot(
    1:length(results_multi[[1]]$vb$E_tau_u_history),
    results_multi[[1]]$vb$E_tau_u_history,
    type = 'l',
    lwd  = 2,
    col  = '#1b9e77',
    xlab = 'Iteration',
    ylab = 'E[tau_u]',
    main = 'Comparison: E[tau_u] Convergence (varying Q, fixed N=300)',
    xlim = c(1, max_len_tau),
    ylim = range(c(sapply(results_multi, function(r) r$vb$E_tau_u_history), tau_u_true)))
  
  for (i in 2:length(results_multi)) {
    lines(1:length(results_multi[[i]]$vb$E_tau_u_history), 
          results_multi[[i]]$vb$E_tau_u_history, 
          col = c('#7570b3', '#e7298a', '#d95f02', '#66a61e')[i-1], 
          lwd = 2)
  }
  
  abline(h = tau_u_true, col = 'red', lty = 2, lwd = 2)
  
  legend('topright',
         legend = c('Q=5', 'Q=10', 'Q=20', 'Q=50', 'Q=100', 'True value'),
         col    = c('#1b9e77', '#7570b3', '#e7298a', '#d95f02', '#66a61e', 'red'),
         lty    = c(rep(1, 5), 2),
         lwd    = 2,
         cex    = 0.8)
  
  # ELBO convergence for all configurations
  max_len_elbo <- max(sapply(results_multi, function(r) length(r$vb$elbo_history)))
  
  plot(
    1:length(results_multi[[1]]$vb$elbo_history),
    results_multi[[1]]$vb$elbo_history,
    type = 'l',
    lwd  = 2,
    col  = '#1b9e77',
    xlab = 'Iteration',
    ylab = 'ELBO',
    main = 'Comparison: ELBO Convergence (varying Q, fixed N=300)',
    xlim = c(1, max_len_elbo),
    ylim = range(sapply(results_multi, function(r) r$vb$elbo_history)))
  
  for (i in 2:length(results_multi)) {
    lines(1:length(results_multi[[i]]$vb$elbo_history), 
          results_multi[[i]]$vb$elbo_history, 
          col = c('#7570b3', '#e7298a', '#d95f02', '#66a61e')[i-1], 
          lwd = 2)
  }
  
  legend('bottomright',
         legend = c('Q=5', 'Q=10', 'Q=20', 'Q=50', 'Q=100'),
         col    = c('#1b9e77', '#7570b3', '#e7298a', '#d95f02', '#66a61e'),
         lty    = 1,
         lwd    = 2,
         cex    = 0.8)
  grid()
} else {
  plot.new()
  text(0.5, 0.5, "Convergence history not available\n(Using Dr John's original functions)", 
       cex = 1.5, col = "gray50")
}
```

```{r plot_tau_u_comparison, fig.width=14, fig.height=10, eval=(model_type=="M3")}
# Create multi-panel comparison plot as requested by Dr John
# Focus on τ_u posterior distributions across different group sizes

plot_list <- list()

for (i in seq_along(results_multi)) {
  result <- results_multi[[i]]
  config <- result$config
  
  # VB posterior: Gamma(a_u_new, b_u_new)
  a_vb <- result$vb$a_u_new
  b_vb <- result$vb$b_u_new
  
  # Calculate VB range
  vb_mean <- a_vb / b_vb
  vb_sd <- sqrt(a_vb) / b_vb
  vb_min <- max(0, vb_mean - 4 * vb_sd)
  vb_max <- vb_mean + 4 * vb_sd
  
  # If HMC available, extend range to include both distributions
  if (!is.null(result$gibbs)) {
    gibbs_tau_u <- result$gibbs[, "tau_u"]
    hmc_min <- quantile(gibbs_tau_u, 0.001)
    hmc_max <- quantile(gibbs_tau_u, 0.999)
    
    x_min <- min(vb_min, hmc_min, tau_u_true * 0.5)
    x_max <- max(vb_max, hmc_max, tau_u_true * 3)
  } else {
    x_min <- min(vb_min, tau_u_true * 0.5)
    x_max <- max(vb_max, tau_u_true * 3)
  }
  
  x_range <- seq(x_min, x_max, length.out = 500)
  vb_density <- dgamma(x_range, shape = a_vb, rate = b_vb)
  
  df_plot <- data.frame(
    tau_u   = x_range,
    density = vb_density,
    method  = "VB",
    type    = "solid"
  )
  
  # Add Gibbs if available and calculate SD ratio
  sd_ratio_text <- ""
  if (!is.null(result$gibbs)) {
    dens_gibbs <- density(gibbs_tau_u, adjust = 1.5)
    
    df_gibbs <- data.frame(
      tau_u   = dens_gibbs$x,
      density = dens_gibbs$y,
      method  = "Gibbs",
      type    = "dashed"
    )
    
    df_plot <- rbind(df_plot, df_gibbs)
    
    # Calculate SD ratio
    vb_sd <- sqrt(a_vb) / b_vb
    gibbs_sd <- sd(gibbs_tau_u)
    sd_ratio <- vb_sd / gibbs_sd
    sd_ratio_text <- glue(" | SD ratio: {round(sd_ratio, 3)}")
  }
  
  # Create plot
  p_tau <- ggplot(df_plot, aes(x = tau_u, y = density, color = method, linetype = method)) +
    geom_line(linewidth = 1.2) +
    geom_vline(xintercept = tau_u_true, color = "red", linetype = "dotted", linewidth = 0.8) +
    scale_color_manual(
      values = c("VB" = "black", "Gibbs" = "#E7298A")
    ) +
    scale_linetype_manual(
      values = c("VB" = "solid", "Gibbs" = "dashed")
    ) +
    labs(
      title = config$label,
      subtitle = glue("VB E[τ_u] = {round(result$vb$E_tau_u, 3)}{sd_ratio_text}"),
      x = expression(tau[u]),
      y = "Density"
    ) +
    theme_minimal() +
    theme(
      legend.position = "top",
      plot.title = element_text(size = 12, face = "bold"),
      plot.subtitle = element_text(size = 10)
    )
  
  plot_list[[i]] <- p_tau
}

# Combine all 5 plots into a grid (2 rows, 3 columns)
combined_tau_u <- (plot_list[[1]] | plot_list[[2]] | plot_list[[3]]) /
                  (plot_list[[4]] | plot_list[[5]] | plot_spacer()) +
  plot_annotation(
    title = "Effect of Sample Size Per Group on τ_u Posterior",
    subtitle = "VB approximation quality with sufficient groups for variance component estimation",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold"),
      plot.subtitle = element_text(size = 12)
    )
  )

# Save plot
ggsave(
  filename = "../figs/tau_u_sample_size_comparison.png",
  plot     = combined_tau_u,
  width    = 14,
  height   = 10,
  dpi      = 300
)

cat("τ_u comparison plot saved to figs/tau_u_sample_size_comparison.png\n")

# Display
img_tau_u <- readPNG("../figs/tau_u_sample_size_comparison.png")
grid.newpage()
grid.raster(img_tau_u)
```

```{r plot_tau_u_overlay, fig.width=14, fig.height=6, eval=(model_type=="M3")}
# Create 2-panel overlay plot: All Gibbs together, All VB together

# Prepare data for Gibbs panel
if (run_gibbs) {
  gibbs_combined <- data.frame()
  
  for (i in seq_along(results_multi)) {
    result <- results_multi[[i]]
    config <- result$config
    gibbs_tau_u <- result$gibbs[, "tau_u"]
    
    dens_gibbs <- density(gibbs_tau_u, adjust = 1.5)
    
    df_temp <- data.frame(
      tau_u   = dens_gibbs$x,
      density = dens_gibbs$y,
      config  = config$label
    )
    
    gibbs_combined <- rbind(gibbs_combined, df_temp)
  }
  
  # Gibbs panel
  p_gibbs <- ggplot(gibbs_combined, aes(x = tau_u, y = density, color = config)) +
    geom_line(linewidth = 1.2) +
    geom_vline(xintercept = tau_u_true, color = "red", linetype = "dotted", linewidth = 0.8) +
    scale_color_manual(
      values = c(
        "Q=5 (n=60 per group)"  = "gray50",
        "Q=10 (n=30 per group)" = "#d95f02",
        "Q=20 (n=15 per group)" = "#7570b3",
        "Q=50 (n=6 per group)"  = "#e7298a",
        "Q=100 (n=3 per group)" = "#1b9e77"
      )
    ) +
    coord_cartesian(xlim = c(0, 8)) +
    labs(
      title = "Gibbs Sampling Posteriors",
      subtitle = "All configurations show similar distributions",
      x = expression(tau[u]),
      y = "Density",
      color = "Configuration"
    ) +
    theme_minimal() +
    theme(
      legend.position = "right",
      legend.text = element_text(size = 9),
      legend.title = element_text(size = 10, face = "bold"),
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 11)
    )
}

# Prepare data for VB panel
vb_combined <- data.frame()

for (i in seq_along(results_multi)) {
  result <- results_multi[[i]]
  config <- result$config
  
  a_vb <- result$vb$a_u_new
  b_vb <- result$vb$b_u_new
  
  # Use broad range to show all VB distributions
  x_range <- seq(0, 20, length.out = 500)
  vb_density <- dgamma(x_range, shape = a_vb, rate = b_vb)
  
  df_temp <- data.frame(
    tau_u   = x_range,
    density = vb_density,
    config  = config$label
  )
  
  vb_combined <- rbind(vb_combined, df_temp)
}

# VB panel
p_vb <- ggplot(vb_combined, aes(x = tau_u, y = density, color = config)) +
  geom_line(linewidth = 1.2) +
  geom_vline(xintercept = tau_u_true, color = "red", linetype = "dotted", linewidth = 0.8) +
  scale_color_manual(
    values = c(
      "Q=5 (n=60 per group)"  = "gray50",
      "Q=10 (n=30 per group)" = "#d95f02",
      "Q=20 (n=15 per group)" = "#7570b3",
      "Q=50 (n=6 per group)"  = "#e7298a",
      "Q=100 (n=3 per group)" = "#1b9e77"
    )
  ) +
  coord_cartesian(xlim = c(0, 8)) +
  labs(
    title = "VB Posteriors",
    subtitle = "Consistent performance with sufficient groups",
    x = expression(tau[u]),
    y = "Density",
    color = "Configuration"
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11)
  )

# Combine panels
if (run_gibbs) {
  combined_overlay <- p_gibbs | p_vb
  plot_title <- "Comparison: Gibbs vs VB Across All Configurations"
  plot_subtitle <- "Gibbs posteriors are consistent; VB posteriors vary dramatically with sample size per group"
  plot_width <- 14
} else {
  combined_overlay <- p_vb
  plot_title <- "VB Posteriors Across All Configurations"
  plot_subtitle <- "VB posterior quality varies dramatically with sample size per group"
  plot_width <- 8
}

combined_overlay <- combined_overlay +
  plot_annotation(
    title = plot_title,
    subtitle = plot_subtitle,
    theme = theme(
      plot.title = element_text(size = 16, face = "bold", margin = margin(b = 10)),
      plot.subtitle = element_text(size = 12, margin = margin(b = 20))
    )
  ) &
  theme(
    legend.position = "top",
    legend.box = "horizontal",
    legend.margin = margin(t = 10, b = 15),
    legend.spacing.x = unit(0.5, "cm"),
    plot.margin = margin(t = 15, r = 10, b = 10, l = 10)
  )

# Save plot
ggsave(
  filename = "../figs/tau_u_overlay_comparison.png",
  plot     = combined_overlay,
  width    = plot_width,
  height   = 7,
  dpi      = 300
)

cat("τ_u overlay comparison plot saved to figs/tau_u_overlay_comparison.png\n")

# Display
img_overlay <- readPNG("../figs/tau_u_overlay_comparison.png")
grid.newpage()
grid.raster(img_overlay)
```

```{r dr_john_reference_plot, eval=(model_type=="M3"), fig.width=10, fig.height=8}
# Generate MY plot in Dr John's exact style
# Single panel with all Gibbs (solid) and VB (dashed) overlaid

cat("\n========================================\n")
cat("My τ_u Comparison (Dr John's Style)\n")
cat("========================================\n\n")

# Prepare data: combine all Gibbs chains for each Q
gibbs_combined <- list()
vb_params <- list()

for (i in seq_along(results_multi)) {
  cfg <- group_configs[[i]]
  q_val <- cfg$q
  
  if (run_gibbs) {
    # results_multi[[i]]$gibbs is a matrix from run_gibbs_sampler
    # tau_u column name is "tau_u"
    gibbs_matrix <- results_multi[[i]]$gibbs
    gibbs_combined[[paste0("q", q_val)]] <- gibbs_matrix[, "tau_u"]
  }
  
  # VB gamma parameters from results_multi
  vb_result <- results_multi[[i]]$vb
  a_param <- vb_result$a_u_new
  b_param <- vb_result$b_u_new
  vb_params[[paste0("q", q_val)]] <- list(a = a_param, b = b_param)
}

# Create plot matching Dr John's style
png(filename = "../figs/my_tau_u_comparison.png", width = 10, height = 8, units = "in", res = 300)

# Colors for all 5 Q values
colors <- c("black", "red", "green3", "blue", "purple")
q_values <- c(5, 10, 20, 50, 100)

# Start with first Gibbs density
if (run_gibbs) {
  plot(density(gibbs_combined$q5), 
       xlab = expression(tau['u']), 
       main = '', 
       ylim = c(0, 2.5),
       xlim = c(0, 8),
       lwd = 2,
       col = colors[1])
  
  # Add remaining Gibbs densities
  lines(density(gibbs_combined$q10), col = colors[2], lwd = 2)
  lines(density(gibbs_combined$q20), col = colors[3], lwd = 2)
  lines(density(gibbs_combined$q50), col = colors[4], lwd = 2)
  lines(density(gibbs_combined$q100), col = colors[5], lwd = 2)
  
  # Add VB approximations (dashed)
  curve(dgamma(x, vb_params$q5$a, vb_params$q5$b), 
        add = TRUE, lty = 2, lwd = 2, col = colors[1])
  curve(dgamma(x, vb_params$q10$a, vb_params$q10$b), 
        add = TRUE, lty = 2, lwd = 2, col = colors[2])
  curve(dgamma(x, vb_params$q20$a, vb_params$q20$b), 
        add = TRUE, lty = 2, lwd = 2, col = colors[3])
  curve(dgamma(x, vb_params$q50$a, vb_params$q50$b), 
        add = TRUE, lty = 2, lwd = 2, col = colors[4])
  curve(dgamma(x, vb_params$q100$a, vb_params$q100$b), 
        add = TRUE, lty = 2, lwd = 2, col = colors[5])
  
  # Legend
  legend('topright', 
         col = c(colors, "black", "black"),
         lty = c(0, 0, 0, 0, 0, 1, 2),
         lwd = c(NA, NA, NA, NA, NA, 2, 2),
         pch = c(19, 19, 19, 19, 19, NA, NA),
         legend = c('q=5', 'q=10', 'q=20', 'q=50', 'q=100', 'Posterior (Gibbs)', 'VB approximation'),
         cex = 0.9)
} else {
  # VB only version
  curve(dgamma(x, vb_params$q5$a, vb_params$q5$b),
        from = 0, to = 8,
        xlab = expression(tau['u']),
        ylab = "Density",
        main = '',
        ylim = c(0, 2.5),
        lwd = 2,
        col = colors[1])
  
  curve(dgamma(x, vb_params$q10$a, vb_params$q10$b),
        add = TRUE, lwd = 2, col = colors[2])
  curve(dgamma(x, vb_params$q20$a, vb_params$q20$b),
        add = TRUE, lwd = 2, col = colors[3])
  curve(dgamma(x, vb_params$q50$a, vb_params$q50$b),
        add = TRUE, lwd = 2, col = colors[4])
  curve(dgamma(x, vb_params$q100$a, vb_params$q100$b),
        add = TRUE, lwd = 2, col = colors[5])
  
  legend('topright',
         col = colors,
         lty = 1,
         lwd = 2,
         legend = c('q=5', 'q=10', 'q=20', 'q=50', 'q=100'),
         cex = 0.9)
}

# Add vertical line at true value
abline(v = tau_u_true, lty = 3, col = "gray40", lwd = 1.5)
text(tau_u_true, 2.3, labels = expression(tau[u]^true), pos = 4, cex = 0.9, col = "gray40")

dev.off()

cat("My plot saved to figs/my_tau_u_comparison.png\n")
```

```{r display_my_plot, eval=(model_type=="M3"), echo=FALSE, out.width='80%', fig.align='center'}
# Display my plot with proper aspect ratio using include_graphics
knitr::include_graphics("../figs/my_tau_u_comparison.png")
```

```{r load_dr_john_rds, eval=(model_type=="M3"), fig.width=10, fig.height=8}
# Load Dr John's reference results from RDS
cat("\n========================================\n")
cat("Loading Dr John's Reference Data (RDS)\n")
cat("========================================\n\n")

# Use absolute path to ensure it works during knitting
project_root <- "d:/github/VI1"
rds_path <- file.path(project_root, "results", "dr_john_reference_tau_u.rds")

if (file.exists(rds_path)) {
  cat("Loading:", rds_path, "\n")
  dr_john_ref <- readRDS(rds_path)
  
  # Check structure
  cat("\nVB structure check:\n")
  cat("  q5 VB class:", class(dr_john_ref$vb$q5), "\n")
  if (is.list(dr_john_ref$vb$q5)) {
    cat("  q5 VB names:", names(dr_john_ref$vb$q5), "\n")
    cat("  q5$a =", dr_john_ref$vb$q5$a, "  q5$b =", dr_john_ref$vb$q5$b, "\n")
  } else {
    cat("  q5 VB values:", dr_john_ref$vb$q5, "\n")
  }
  
  cat("\nCreating plot from Dr John's saved RDS data...\n")
  
  colors_rds <- c("black", "red", "green3", "blue", "magenta")
  
  # Save plot to PNG file
  png(filename = file.path(project_root, "figs", "my_from_rds_tau_u_comparison.png"),
      width = 3500, height = 2800, res = 300)
  
  plot(density(dr_john_ref$gibbs$q5),
       xlab=expression(tau['u']),
       main='Recreated from Dr John\'s RDS File',
       ylim=c(0, 2.5),
       xlim=c(0, 8),
       lwd=2,
       col=colors_rds[1])
  
  lines(density(dr_john_ref$gibbs$q10), col=colors_rds[2], lwd=2)
  lines(density(dr_john_ref$gibbs$q20), col=colors_rds[3], lwd=2)
  lines(density(dr_john_ref$gibbs$q50), col=colors_rds[4], lwd=2)
  lines(density(dr_john_ref$gibbs$q100), col=colors_rds[5], lwd=2)
  
  # Add VB approximations - check if data is vector or list
  if (is.list(dr_john_ref$vb$q5)) {
    # VB stored as list(a=, b=)
    curve(dgamma(x, dr_john_ref$vb$q5$a, dr_john_ref$vb$q5$b), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[1])
    curve(dgamma(x, dr_john_ref$vb$q10$a, dr_john_ref$vb$q10$b), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[2])
    curve(dgamma(x, dr_john_ref$vb$q20$a, dr_john_ref$vb$q20$b), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[3])
    curve(dgamma(x, dr_john_ref$vb$q50$a, dr_john_ref$vb$q50$b), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[4])
    curve(dgamma(x, dr_john_ref$vb$q100$a, dr_john_ref$vb$q100$b), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[5])
  } else {
    # VB stored as vector c(a, b)
    curve(dgamma(x, dr_john_ref$vb$q5[1], dr_john_ref$vb$q5[2]), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[1])
    curve(dgamma(x, dr_john_ref$vb$q10[1], dr_john_ref$vb$q10[2]), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[2])
    curve(dgamma(x, dr_john_ref$vb$q20[1], dr_john_ref$vb$q20[2]), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[3])
    curve(dgamma(x, dr_john_ref$vb$q50[1], dr_john_ref$vb$q50[2]), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[4])
    curve(dgamma(x, dr_john_ref$vb$q100[1], dr_john_ref$vb$q100[2]), 
          add = TRUE, lty = 2, lwd = 2, col = colors_rds[5])
  }
  
  legend('topright',
         col=c(colors_rds, "black", "black"),
         lty=c(0,0,0,0,0,1,2),
         lwd=c(NA,NA,NA,NA,NA,2,2),
         pch=c(19,19,19,19,19,NA,NA),
         legend=c('q=5', 'q=10', 'q=20', 'q=50', 'q=100', 'Posterior (Gibbs)', 'VB approximation'),
         cex=0.9)
  
  abline(v=0.5, lty=3, col="gray40", lwd=1.5)
  text(0.5, 2.3, labels=expression(tau[u]^true*" = 0.5"), pos=4, cex=0.9, col="gray40")
  
  dev.off()
  
  cat("Plot from RDS saved to figs/my_from_rds_tau_u_comparison.png\n")
  
} else {
  cat("WARNING: RDS file not found at:", rds_path, "\n")
  cat("Run 'Code for David Ewing Random intercept example.R' to generate it.\n")
}
```

```{r display_rds_plot, eval=(model_type=="M3"), echo=FALSE, out.width='80%', fig.align='center'}
# Display plot recreated from RDS
rds_plot_path <- "../figs/my_from_rds_tau_u_comparison.png"
if (file.exists(rds_plot_path)) {
  knitr::include_graphics(rds_plot_path)
}
```

```{r three_panel_comparison, eval=(model_type=="M3"), echo=FALSE, results='asis'}
# Create 3-panel comparison
cat("\n## Three-Panel Validation Comparison\n\n")

project_root <- "d:/github/VI1"
dr_john_baseline <- file.path(project_root, "figs", "dr_john_tau_QPosteriorVB_reference.png")
my_from_rds <- file.path(project_root, "figs", "my_from_rds_tau_u_comparison.png")
my_new_run <- file.path(project_root, "figs", "my_tau_u_comparison.png")

panel1_exists <- file.exists(dr_john_baseline)
panel2_exists <- file.exists(my_from_rds)
panel3_exists <- file.exists(my_new_run)

cat("Panel status:\n")
cat("- Dr John's baseline PNG:", ifelse(panel1_exists, "✓", "✗"), "\n")
cat("- My plot from RDS:", ifelse(panel2_exists, "✓", "✗"), "\n")
cat("- My new run with matched params:", ifelse(panel3_exists, "✓", "✗"), "\n\n")
```

```{r three_panel_plots, eval=(model_type=="M3"), echo=FALSE, fig.show='hold', out.width='32%', fig.align='default'}
# Display all three panels side-by-side
project_root <- "d:/github/VI1"

dr_john_baseline <- file.path(project_root, "figs", "dr_john_tau_QPosteriorVB_reference.png")
my_from_rds <- file.path(project_root, "figs", "my_from_rds_tau_u_comparison.png") 
my_new_run <- file.path(project_root, "figs", "my_tau_u_comparison.png")

# Build vector of plots that exist
plots_to_show <- c()
if (file.exists(dr_john_baseline)) plots_to_show <- c(plots_to_show, dr_john_baseline)
if (file.exists(my_from_rds)) plots_to_show <- c(plots_to_show, my_from_rds)
if (file.exists(my_new_run)) plots_to_show <- c(plots_to_show, my_new_run)

# Single include_graphics call with vector (required for side-by-side display)
if (length(plots_to_show) > 0) {
  knitr::include_graphics(plots_to_show)
}
```

```{r three_panel_labels, eval=(model_type=="M3"), echo=FALSE, results='asis'}
# Add labels for the three panels - based on actual display order
label_order <- character(0)
if (file.exists(dr_john_baseline)) label_order <- c(label_order, "Dr John's baseline PNG (from his .R file)")
if (file.exists(my_from_rds)) label_order <- c(label_order, "My recreation from his RDS data")
if (file.exists(my_new_run)) label_order <- c(label_order, "My new run with matched parameters")

if (length(label_order) >= 1) cat("\n**Left:**", label_order[1], " \n")
if (length(label_order) >= 2) cat("**Centre:**", label_order[2], " \n")
if (length(label_order) >= 3) cat("**Right:**", label_order[3], "\n\n")
```

```{r tau_u_diagnostic_ratio, eval=(model_type=="M3"), fig.width=10, fig.height=6}
# Diagnostic: Posterior variance / Prior variance ratio for u's
# As requested by Dr John [0:15:49]
# "When you do badly with tau_u, this ratio will be high. When you do well, this ratio will be low."

cat("\nDiagnostic: Var_posterior(u) / Var_prior(u)\n")
cat("Diagnostic: Var_posterior(u) / Var_prior(u)\n") 

# Prior variance: u_i ~ N(0, 1/tau_u_true)
var_prior_u <- 1 / tau_u_true

# Calculate ratio for each configuration
ratio_data <- data.frame()

for (i in seq_along(results_multi)) {
  result <- results_multi[[i]]
  config <- result$config
  q <- config$q
  
  # VB posterior variances: diagonal of Sigma_betau for u's
  Sigma_betau <- result$vb$Sigma_betau
  var_post_vb_u <- diag(Sigma_betau)[(p+1):(p+q)]
  mean_ratio_vb <- mean(var_post_vb_u / var_prior_u)
  
  # Gibbs posterior variances if available
  if (!is.null(result$gibbs)) {
    var_post_gibbs_u <- sapply(1:q, function(j) {
      var(result$gibbs[, paste0("u", j)])
    })
    mean_ratio_gibbs <- mean(var_post_gibbs_u / var_prior_u)
  } else {
    mean_ratio_gibbs <- NA
  }
  
  # Store results
  ratio_data <- rbind(ratio_data, data.frame(
    Q = q,
    n_per_group = config$nq,
    VB_ratio = mean_ratio_vb,
    Gibbs_ratio = mean_ratio_gibbs,
    label = config$label
  ))
}

print(ratio_data)

cat("\nInterpretation:\n")
cat("- Lower ratio = narrower posteriors = more information learnt\n")
cat("- Narrow posteriors for u → better tau_u estimation in VB\n")
cat("- As n_per_group increases, VB ratio decreases (posteriors concentrate)\n\n")

# Prepare data for plotting
plot_data <- data.frame(
  Q  = ratio_data$Q,
  VB = ratio_data$VB_ratio
)

if (run_gibbs) {
  plot_data$Gibbs <- ratio_data$Gibbs_ratio
  plot_data_long <- tidyr::pivot_longer(plot_data, cols = c(VB, Gibbs), 
                                         names_to = "Method", values_to = "Ratio")
} else {
  plot_data_long <- data.frame(
    Q = plot_data$Q,
    Method = "VB",
    Ratio = plot_data$VB
  )
}

# Create diagnostic plot
p_diagnostic <- ggplot(plot_data_long, aes(x = factor(Q), y = Ratio, color = Method, group = Method)) +
  geom_point(size = 4) +
  geom_line(aes(linetype = Method), size = 1.2) +
  scale_color_manual(
    values = c("VB" = "black", "Gibbs" = "#E7298A")
  ) +
  scale_linetype_manual(
    values = c("VB" = "solid", "Gibbs" = "dashed")
  ) +
  labs(
    title = "Diagnostic: Posterior Variance / Prior Variance Ratio for Random Effects",
    subtitle = "Varying Q (fixed N=300): Lower ratio indicates concentrated posteriors and better τ_u estimation",
    x = "Number of Groups (Q) [n per group = 300/Q]",
    y = "Mean(Var_posterior(u) / Var_prior(u))",
    color = "Method"
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11)
  )

ggsave(
  filename = "../figs/diagnostic_variance_ratio.png",
  plot = p_diagnostic,
  width = 10,
  height = 6,
  dpi = 300
)

img_diagnostic <- readPNG("../figs/diagnostic_variance_ratio.png")
grid.newpage()
grid.raster(img_diagnostic)

cat("\n========================================\n")
cat("Key Finding (Dr John's insight):\n")
cat("As n per group increases (Q decreases from 50→5),\n")
cat("VB posteriors for u become narrower (ratio decreases),\n")
cat("leading to better tau_u estimation.\n")
cat("========================================\n")
```
# Validation: Dr John's Farm Data

## Objective
Replicate Dr John's Lab 9 results exactly using the same farm data, demonstrating that we're running his functions correctly.

```{r farmdata_load, eval=TRUE}
cat("\n========================================\n")
cat("VALIDATION PHASE: Farm Data Replication\n")
cat("========================================\n")

# Load farm data exactly as Dr John did
# Note: When knitting, working directory is the temp folder, so use full path
data <- read.csv("d:/github/VI1/data_raw/farmdata.csv")
K    <- read.csv("d:/github/VI1/data_raw/Kmat.csv", header = FALSE)
K    <- as.matrix(K)
Kinv <- solve(K)

n_farm <- nrow(data)
q_farm <- nrow(Kinv)

# Create design matrices exactly as Dr John did
X_farm <- table(1:n_farm, data$flock)  # flock is fixed effect
Z2     <- table(1:n_farm, data$sire)   # sire random effects
Z3     <- cbind(Z2, table(1:n_farm, data$dam))  # add dam random effects

cat("Data dimensions:\n")
cat("  n (observations):", n_farm, "\n")
cat("  p (fixed effects):", ncol(X_farm), "\n")
cat("  q (random effects):", q_farm, "\n")
cat("  Response range:", round(min(data$y), 2), "to", round(max(data$y), 2), "\n")
```

```{r farmdata_gibbs, eval=TRUE, cache=FALSE}
cat("\n--- Running Gibbs Sampler (3 chains, different starting values) ---\n")

set.seed(2334576)  # Dr John's seed from Lab 9

# Chain 1: taue_0=5, tauu_0=0.2
cat("Chain 1: taue_0=5, tauu_0=0.2...\n")
farm_chain1 <- normalmm.Gibbs(
  iter    = 10000,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  burnin  = 2000,
  taue_0  = 5,
  tauu_0  = 0.2,
  Kinv    = Kinv,
  a.u     = 0.001,
  b.u     = 0.001,
  a.e     = 0.001,
  b.e     = 0.001
)

# Chain 2: taue_0=1, tauu_0=1
cat("Chain 2: taue_0=1, tauu_0=1...\n")
farm_chain2 <- normalmm.Gibbs(
  iter    = 10000,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  burnin  = 2000,
  taue_0  = 1,
  tauu_0  = 1,
  Kinv    = Kinv,
  a.u     = 0.001,
  b.u     = 0.001,
  a.e     = 0.001,
  b.e     = 0.001
)

# Chain 3: taue_0=0.2, tauu_0=3
cat("Chain 3: taue_0=0.2, tauu_0=3...\n")
farm_chain3 <- normalmm.Gibbs(
  iter    = 10000,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  burnin  = 2000,
  taue_0  = 0.2,
  tauu_0  = 3,
  Kinv    = Kinv,
  a.u     = 0.001,
  b.u     = 0.001,
  a.e     = 0.001,
  b.e     = 0.001
)

cat("Gibbs sampling complete for all 3 chains.\n")
```

```{r farmdata_vb, eval=TRUE}
cat("\n--- Running Variational Bayes (3 starting values) ---\n")

set.seed(2334576)

# VB 1: taue_0=0.2, tauu_0=0.2
cat("VB 1: taue_0=0.2, tauu_0=0.2...\n")
farm_vb1 <- VB.mm(
  epsilon = 1e-5,
  iter    = 2000,
  Kinv    = Kinv,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  taue_0  = 0.2,
  tauu_0  = 0.2,
  u0      = rnorm(q_farm),
  beta0   = rnorm(ncol(X_farm)),
  a.e     = 0.001,
  g.e     = 0.001,
  a.u     = 0.001,
  g.u     = 0.001
)

# VB 2: taue_0=5, tauu_0=1
cat("VB 2: taue_0=5, tauu_0=1...\n")
farm_vb2 <- VB.mm(
  epsilon = 1e-5,
  iter    = 2000,
  Kinv    = Kinv,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  taue_0  = 5,
  tauu_0  = 1,
  u0      = rnorm(q_farm),
  beta0   = rnorm(ncol(X_farm)),
  a.e     = 0.001,
  g.e     = 0.001,
  a.u     = 0.001,
  g.u     = 0.001
)

# VB 3: taue_0=1, tauu_0=5
cat("VB 3: taue_0=1, tauu_0=5...\n")
farm_vb3 <- VB.mm(
  epsilon = 1e-5,
  iter    = 2000,
  Kinv    = Kinv,
  Z       = Z3,
  X       = X_farm,
  y       = data$y,
  taue_0  = 1,
  tauu_0  = 5,
  u0      = rnorm(q_farm),
  beta0   = rnorm(ncol(X_farm)),
  a.e     = 0.001,
  g.e     = 0.001,
  a.u     = 0.001,
  g.u     = 0.001
)

cat("VB convergence iterations:\n")
cat("  VB1:", farm_vb1$iter, "\n")
cat("  VB2:", farm_vb2$iter, "\n")
cat("  VB3:", farm_vb3$iter, "\n")
```

```{r farmdata_comparison, eval=TRUE}
cat("\n========================================\n")
cat("PARAMETER ESTIMATES COMPARISON\n")
cat("========================================\n")

# Combine all Gibbs chains
farm_chain_all <- rbind(farm_chain1$par, farm_chain2$par, farm_chain3$par)

# Posterior means from Gibbs (gold standard)
gibbs_means <- colMeans(farm_chain_all)

# Compare beta and u parameters (first 15 columns)
n_betau <- ncol(X_farm) + q_farm
comparison_betau <- data.frame(
  Parameter = colnames(farm_chain1$par)[1:n_betau],
  VB1       = farm_vb1$betau_mean,
  VB2       = farm_vb2$betau_mean,
  VB3       = farm_vb3$betau_mean,
  Gibbs     = gibbs_means[1:n_betau]
)

print(comparison_betau)

# Precision parameters
cat("\n--- Precision Parameters ---\n")

# Get column indices for variance components (last 2 columns)
n_cols <- ncol(farm_chain_all)
sigma_b_col <- farm_chain_all[, n_cols - 1]  # sigma_b (random effect SD)
sigma_e_col <- farm_chain_all[, n_cols]      # sigma_e (residual SD)

cat("tau_e (residual precision):\n")
cat("  VB1 E[tau_e]:", round(farm_vb1$tau_e[1] / farm_vb1$tau_e[2], 4), "\n")
cat("  VB2 E[tau_e]:", round(farm_vb2$tau_e[1] / farm_vb2$tau_e[2], 4), "\n")
cat("  VB3 E[tau_e]:", round(farm_vb3$tau_e[1] / farm_vb3$tau_e[2], 4), "\n")
cat("  Gibbs mean:", round(mean(sigma_e_col^(-2)), 4), "\n")

cat("\ntau_u (random effect precision):\n")
cat("  VB1 E[tau_u]:", round(farm_vb1$tau_u[1] / farm_vb1$tau_u[2], 4), "\n")
cat("  VB2 E[tau_u]:", round(farm_vb2$tau_u[1] / farm_vb2$tau_u[2], 4), "\n")
cat("  VB3 E[tau_u]:", round(farm_vb3$tau_u[1] / farm_vb3$tau_u[2], 4), "\n")
cat("  Gibbs mean:", round(mean(sigma_b_col^(-2)), 4), "\n")

cat("\nsigma_e (residual SD):\n")
cat("  Gibbs mean:", round(mean(sigma_e_col), 4), "\n")

cat("\nsigma_u (random effect SD):\n")
cat("  Gibbs mean:", round(mean(sigma_b_col), 4), "\n")

cat("\n========================================\n")
cat("VALIDATION RESULT:\n")
cat("If these values match Dr John's Lab 9 output,\n")
cat("we have successfully replicated his analysis\n")
cat("using his exact functions and data.\n")
cat("========================================\n")
```

\newpage

# Dr John's Exact Replication Test (Flat Priors, All 5 Q Values)

This section tests whether we can replicate Dr John's **exact results** by:

1. **Using his exact flat priors**: `a.u=0, b.u=0, a.e=0, b.e=0`
2. **removing all ridge regularisation**: Pure version of his function
3. **testing all 5 Q values**: 5, 10, 20, 50, 100
4. **using his exact data generation**: Same seed and methodology

**hypothesis**: If his code works with flat priors and no ridge, ours should too.

```{r dr_john_gibbs_pure, eval=(model_type=="M3")}
# Dr John's PURE Gibbs sampler - exactly as he wrote it,  
normalmm.Gibbs.pure <- function(iter, Z, X, y, burnin, taue_0, tauu_0, Kinv, a.u, b.u, a.e, b.e){
  n     <- length(y)
  p     <- dim(X)[2]
  q     <- dim(Z)[2]
  tauu  <- tauu_0
  taue  <- taue_0
  beta0 <- rnorm(p)
  u0    <- rnorm(q, 0, sd = 1/sqrt(tauu))
  
  W <- cbind(X, Z)
  WTW <- crossprod(W)
  WTy <- crossprod(W, y)
  
  par <- matrix(0, iter, p+q+2)
  lppd <- matrix(0, iter, n)
  
  I0  <- diag(p+q)
  diag(I0)[1:p] <- 0
  I0[-c(1:p), -c(1:p)] <- Kinv
  
  for(i in 1:iter){
    uKinvu <- t(u0)%*%Kinv%*%u0
    uKinvu <- as.numeric(uKinvu)
    tauu <- rgamma(1, a.u+0.5*q, b.u+0.5*uKinvu)
    Prec <- WTW*taue + tauu*I0
    P.var <- solve(Prec)
    P.mean <- P.var%*%WTy*taue
    betau <- mvtnorm::rmvnorm(1, mean=P.mean, sigma=P.var)
    betau <- as.numeric(betau)
    err   <- y-W%*%betau
    taue  <- rgamma(1, a.e+0.5*n, b.e+0.5*sum(err^2))
    par[i,] <- c(betau, tauu, taue)
    beta0  <- betau[1:p]
    u0     <- betau[(p+1):(p+q)]
    lppd[i,] <- dnorm(y, mean=as.numeric(W%*%betau), sd=1/sqrt(taue))
  }
  
  lppd      <- lppd[-c(1:burnin),]
  lppdest <- sum(log(colMeans(lppd)))
  pwaic2  <- sum(apply(log(lppd), 2, FUN=var))
  par     <- par[-c(1:burnin),]
  colnames(par) <- c(paste('beta', 1:p, sep=''), paste('u', 1:q, sep=''), 'tau_u', 'tau_e')
  mresult <- list(par, lppdest, pwaic2)
  names(mresult) <- c('par', 'lppd', 'pwaic')
  return(mresult)
}

cat("\n========================================\n")
cat("Dr John's Exact Replication Test\n")
cat("========================================\n\n")
cat("Testing with:\n")
cat("  - Flat priors: a.u=0, b.u=0, a.e=0, b.e=0\n")
cat("  - No ridge regularisation\n")
cat("  - All 5 Q values: 5, 10, 20, 50, 100\n")
cat("  - His exact data generation\n\n")
```

```{r dr_john_data_all_q, eval=(model_type=="M3")}
set.seed(82171165)

n_pure <- 300
beta_pure <- c(0.5, -2, 3)
X_pure <- cbind(1, matrix(rnorm(n_pure*2), n_pure, 2))

# Store all configurations
pure_data_list <- list()
q_values_pure <- c(5, 10, 20, 50, 100)

cat("Generating data for all Q configurations...\n")

# Q=5
u.sim1 <- rnorm(5, 0, 1)
u.sim1 <- scale(u.sim1)
Z1     <- table(1:n_pure, rep(1:5, n_pure/5))
y1     <- as.vector(X_pure %*% beta_pure + Z1 %*% u.sim1 + rnorm(n_pure, 0, sqrt(2)))
pure_data_list[[1]] <- list(Z=Z1, y=y1, q=5)

# Q=10
u.sim2 <- rnorm(10, 0, 1)
u.sim2 <- scale(u.sim2)
Z2     <- table(1:n_pure, rep(1:10, n_pure/10))
y2     <- as.vector(y1) - as.vector(Z1 %*% u.sim1) + as.vector(Z2 %*% u.sim2)
pure_data_list[[2]] <- list(Z=Z2, y=y2, q=10)

# Q=20
u.sim3 <- rnorm(20, 0, 1)
u.sim3 <- scale(u.sim3)
Z3     <- table(1:n_pure, rep(1:20, n_pure/20))
y3     <- as.vector(y2) - as.vector(Z2 %*% u.sim2) + as.vector(Z3 %*% u.sim3)
pure_data_list[[3]] <- list(Z=Z3, y=y3, q=20)

# Q=50
u.sim4 <- rnorm(50, 0, 1)
u.sim4 <- scale(u.sim4)
Z4     <- table(1:n_pure, rep(1:50, n_pure/50))
y4     <- as.vector(y3) - as.vector(Z3 %*% u.sim3) + as.vector(Z4 %*% u.sim4)
pure_data_list[[4]] <- list(Z=Z4, y=y4, q=50)

# Q=100
u.sim5 <- rnorm(100, 0, 1)
u.sim5 <- scale(u.sim5)
Z5     <- table(1:n_pure, rep(1:100, n_pure/100))
y5     <- as.vector(y4) - as.vector(Z4 %*% u.sim4) + as.vector(Z5 %*% u.sim5)
pure_data_list[[5]] <- list(Z=Z5, y=y5, q=100)

cat("Data generation complete.\n")
```

```{r dr_john_gibbs_all_q, eval=(model_type=="M3")}
cat("\n--- Running Gibbs with Flat Priors (3 chains per Q) ---\n")

pure_gibbs_results <- list()

for(i in 1:5) {
  q_val     <- q_values_pure[i]
  Z_data    <- pure_data_list[[i]]$Z
  y_data    <- pure_data_list[[i]]$y
  Kinv_data <- diag(q_val)
  
  cat(glue("\nQ={q_val} (n={n_pure/q_val} per group):\n"))
  
  # Chain 1
  cat("  Chain 1...")
  chain1 <- tryCatch({
    normalmm.Gibbs.pure(
      iter=10000, Z=Z_data, X=X_pure, y=y_data, burnin=2000,
      taue_0=3, tauu_0=0.5, Kinv=Kinv_data,
      a.u=0, b.u=0, a.e=0, b.e=0
    )
  }, error = function(e) {
    cat(" ERROR:", e$message, "\n")
    return(NULL)
  })
  if (!is.null(chain1)) cat(" Done\n")
  
  # Chain 2
  cat("  Chain 2...")
  chain2 <- tryCatch({
    normalmm.Gibbs.pure(
      iter=10000, Z=Z_data, X=X_pure, y=y_data, burnin=2000,
      taue_0=0.5, tauu_0=3, Kinv=Kinv_data,
      a.u=0, b.u=0, a.e=0, b.e=0
    )
  }, error = function(e) {
    cat(" ERROR:", e$message, "\n")
    return(NULL)
  })
  if (!is.null(chain2)) cat(" Done\n")
  
  # Chain 3
  cat("  Chain 3...")
  chain3 <- tryCatch({
    normalmm.Gibbs.pure(
      iter=10000, Z=Z_data, X=X_pure, y=y_data, burnin=2000,
      taue_0=5, tauu_0=5, Kinv=Kinv_data,
      a.u=0, b.u=0, a.e=0, b.e=0
    )
  }, error = function(e) {
    cat(" ERROR:", e$message, "\n")
    return(NULL)
  })
  if (!is.null(chain3)) cat(" Done\n")
  
  pure_gibbs_results[[i]] <- list(
    chain1  = chain1, 
    chain2  = chain2, 
    chain3  = chain3, 
    q       = q_val,
    success = !is.null(chain1) && !is.null(chain2) && !is.null(chain3)
  )
}

cat("\n========================================\n")
cat("Flat Prior Test Results:\n")
for(i in 1:5) {
  status <- if(pure_gibbs_results[[i]]$success) "✓ SUCCESS" else "✗ FAILED"
  cat(glue("  Q={q_values_pure[i]}: {status}\n"))
}
cat("========================================\n")
```

```{r dr_john_vb_all_q, eval=(model_type=="M3")}
cat("\n--- Running VB with Flat Priors (1 run per Q) ---\n")

pure_vb_results <- list()

for(i in 1:5) {
  q_val <- q_values_pure[i]
  Z_data <- pure_data_list[[i]]$Z
  y_data <- pure_data_list[[i]]$y
  Kinv_data <- diag(q_val)
  
  cat(glue("Q={q_val}..."))
  
  vb_result <- tryCatch({
    VB.mm(
      epsilon=1e-6, iter=100, Kinv=Kinv_data,
      Z=Z_data, X=X_pure, y=y_data,
      taue_0=3, tauu_0=0.5,
      u0=rnorm(q_val), beta0=rnorm(3),
      a.e=0, g.e=0, a.u=0, g.u=0
    )
  }, error = function(e) {
    cat(" ERROR:", e$message, "\n")
    return(NULL)
  })
  
  if (!is.null(vb_result)) {
    cat(" Done (", vb_result$iter, " iterations)\n", sep="")
  }
  
  pure_vb_results[[i]] <- list(vb=vb_result, q=q_val, success=!is.null(vb_result))
}

cat("\nVB complete.\n")
```

```{r dr_john_pure_plot, eval=(model_type=="M3"), fig.width=10, fig.height=8}
cat("\n--- Creating Comparison Plot ---\n")

# Combine successful Gibbs chains
colors_pure <- c("black", "red", "green3", "blue", "magenta")
tau_u_gibbs_pure <- list()
tau_u_vb_pure <- list()

for(i in 1:5) {
  if (pure_gibbs_results[[i]]$success) {
    q_val  <- q_values_pure[i]
    p_cols <- p  # number of beta parameters (should be 3, matching p=3)
    
    tau_u_c1 <- pure_gibbs_results[[i]]$chain1$par[, p_cols + q_val + 1]
    tau_u_c2 <- pure_gibbs_results[[i]]$chain2$par[, p_cols + q_val + 1]
    tau_u_c3 <- pure_gibbs_results[[i]]$chain3$par[, p_cols + q_val + 1]
    
    tau_u_gibbs_pure[[i]] <- c(tau_u_c1, tau_u_c2, tau_u_c3)
  } else {
    tau_u_gibbs_pure[[i]] <- NULL
  }
  
  if (pure_vb_results[[i]]$success) {
    tau_u_vb_pure[[i]] <- pure_vb_results[[i]]$vb$tau_u
  } else {
    tau_u_vb_pure[[i]] <- NULL
  }
}

# Create plot
png(filename = "../figs/flat_priors_exact_replication.png", width = 10, height = 8, units = "in", res = 300)

# Start with first successful Gibbs
first_idx <- which(sapply(tau_u_gibbs_pure, function(x) !is.null(x)))[1]

if (!is.na(first_idx)) {
  plot(density(tau_u_gibbs_pure[[first_idx]]),
       xlab=expression(tau['u']),
       main='Flat Priors (a=0, b=0) - Exact Replication Test',
       ylim=c(0, 2.5),
       xlim=c(0, 8),
       lwd=2,
       col=colors_pure[first_idx])
  
  # Add remaining Gibbs densities
  for(i in (first_idx+1):5) {
    if (!is.null(tau_u_gibbs_pure[[i]])) {
      lines(density(tau_u_gibbs_pure[[i]]), col=colors_pure[i], lwd=2)
    }
  }
  
  # Add VB approximations
  for(i in 1:5) {
    if (!is.null(tau_u_vb_pure[[i]])) {
      curve(dgamma(x, tau_u_vb_pure[[i]][1], tau_u_vb_pure[[i]][2]),
            add=TRUE, lty=2, lwd=2, col=colors_pure[i])
    }
  }
  
  # Legend
  legend_q <- paste0("q=", q_values_pure)
  legend('topright',
         col=c(colors_pure, "black", "black"),
         lty=c(0,0,0,0,0,1,2),
         lwd=c(NA,NA,NA,NA,NA,2,2),
         pch=c(19,19,19,19,19,NA,NA),
         legend=c(legend_q, 'Posterior (Gibbs)', 'VB approximation'),
         cex=0.9)
  
  abline(v=0.5, lty=3, col="gray40", lwd=1.5)
  text(0.5, 2.3, labels=expression(tau[u]^true*" = 0.5"), pos=4, cex=0.9, col="gray40")
}

dev.off()

cat("Flat priors plot saved to figs/flat_priors_exact_replication.png\n")
```

```{r display_flat_priors_plot, eval=(model_type=="M3"), echo=FALSE, out.width='80%', fig.align='center'}
knitr::include_graphics("../figs/flat_priors_exact_replication.png")
```

```{r flat_priors_summary, eval=(model_type=="M3"), results='asis'}
cat("\n## Flat Priors Test Summary\n\n")
cat("**Question:** Can we replicate Dr John's results with his exact flat priors?\n\n")

success_count <- sum(sapply(pure_gibbs_results, function(x) x$success))
cat(glue("**Result:** {success_count}/5 configurations successful\n\n"))

if (success_count == 5) {
  cat("✓ **All configurations ran successfully!**\n\n")
  cat("This confirms:\n")
  cat("- Dr John's function works with flat priors\n")
  cat("- No ridge regularisation needed\n")
  cat("- My modifications (weak priors + ridge) were unnecessary\n\n")
} else if (success_count >= 3) {
  cat("⚠ **Partial success** - some configurations failed\n\n")
  cat("Failed configurations:\n")
  for(i in 1:5) {
    if (!pure_gibbs_results[[i]]$success) {
      cat(glue("- Q={q_values_pure[i]} (n={n_pure/q_values_pure[i]} per group)\n"))
    }
  }
  cat("\n")
} else {
  cat("✗ **Most configurations failed**\n\n")
  cat("This suggests:\n")
  cat("- Numerical issues are real\n")
  cat("- Ridge regularisation may be necessary\n")
  cat("- Weak priors help stability\n\n")
}
```

\newpage
